<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Eval Review</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@500;600&family=Lora:wght@400;500&display=swap" rel="stylesheet">
  <script src="https://cdn.sheetjs.com/xlsx-0.20.3/package/dist/xlsx.full.min.js" integrity="sha384-EnyY0/GSHQGSxSgMwaIPzSESbqoOLSexfnSMN2AP+39Ckmn92stwABZynq1JyzdT" crossorigin="anonymous"></script>
  <style>
    :root {
      --bg: #faf9f5;
      --surface: #ffffff;
      --border: #e8e6dc;
      --text: #141413;
      --text-muted: #b0aea5;
      --accent: #d97757;
      --accent-hover: #c4613f;
      --green: #788c5d;
      --green-bg: #eef2e8;
      --red: #c44;
      --red-bg: #fceaea;
      --header-bg: #141413;
      --header-text: #faf9f5;
      --radius: 6px;
    }

    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: 'Lora', Georgia, serif;
      background: var(--bg);
      color: var(--text);
      height: 100vh;
      display: flex;
      flex-direction: column;
    }

    /* ---- Header ---- */
    .header {
      background: var(--header-bg);
      color: var(--header-text);
      padding: 1rem 2rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      flex-shrink: 0;
    }
    .header h1 {
      font-family: 'Poppins', sans-serif;
      font-size: 1.25rem;
      font-weight: 600;
    }
    .header .instructions {
      font-size: 0.8rem;
      opacity: 0.7;
      margin-top: 0.25rem;
    }
    .header .progress {
      font-size: 0.875rem;
      opacity: 0.8;
      text-align: right;
    }

    /* ---- Main content ---- */
    .main {
      flex: 1;
      overflow-y: auto;
      padding: 1.5rem 2rem;
      display: flex;
      flex-direction: column;
      gap: 1.25rem;
    }

    /* ---- Sections ---- */
    .section {
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      flex-shrink: 0;
    }
    .section-header {
      font-family: 'Poppins', sans-serif;
      padding: 0.75rem 1rem;
      font-size: 0.75rem;
      font-weight: 500;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      color: var(--text-muted);
      border-bottom: 1px solid var(--border);
      background: var(--bg);
    }
    .section-body {
      padding: 1rem;
    }

    /* ---- Config badge ---- */
    .config-badge {
      display: inline-block;
      padding: 0.2rem 0.625rem;
      border-radius: 9999px;
      font-family: 'Poppins', sans-serif;
      font-size: 0.6875rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.03em;
      margin-left: 0.75rem;
      vertical-align: middle;
    }
    .config-badge.config-primary {
      background: rgba(33, 150, 243, 0.12);
      color: #1976d2;
    }
    .config-badge.config-baseline {
      background: rgba(255, 193, 7, 0.15);
      color: #f57f17;
    }

    /* ---- Prompt ---- */
    .prompt-text {
      white-space: pre-wrap;
      font-size: 0.9375rem;
      line-height: 1.6;
    }

    /* ---- Outputs ---- */
    .output-file {
      border: 1px solid var(--border);
      border-radius: var(--radius);
      overflow: hidden;
    }
    .output-file + .output-file {
      margin-top: 1rem;
    }
    .output-file-header {
      padding: 0.5rem 0.75rem;
      font-size: 0.8rem;
      font-weight: 600;
      color: var(--text-muted);
      background: var(--bg);
      border-bottom: 1px solid var(--border);
      font-family: 'SF Mono', SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }
    .output-file-header .dl-btn {
      font-size: 0.7rem;
      color: var(--accent);
      text-decoration: none;
      cursor: pointer;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      font-weight: 500;
      opacity: 0.8;
    }
    .output-file-header .dl-btn:hover {
      opacity: 1;
      text-decoration: underline;
    }
    .output-file-content {
      padding: 0.75rem;
      overflow-x: auto;
    }
    .output-file-content pre {
      font-size: 0.8125rem;
      line-height: 1.5;
      white-space: pre-wrap;
      word-break: break-word;
      font-family: 'SF Mono', SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace;
    }
    .output-file-content img {
      max-width: 100%;
      height: auto;
      border-radius: 4px;
    }
    .output-file-content iframe {
      width: 100%;
      height: 600px;
      border: none;
    }
    .output-file-content table {
      border-collapse: collapse;
      font-size: 0.8125rem;
      width: 100%;
    }
    .output-file-content table td,
    .output-file-content table th {
      border: 1px solid var(--border);
      padding: 0.375rem 0.5rem;
      text-align: left;
    }
    .output-file-content table th {
      background: var(--bg);
      font-weight: 600;
    }
    .output-file-content .download-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.5rem 1rem;
      background: var(--bg);
      border: 1px solid var(--border);
      border-radius: 4px;
      color: var(--accent);
      text-decoration: none;
      font-size: 0.875rem;
      cursor: pointer;
    }
    .output-file-content .download-link:hover {
      background: var(--border);
    }
    .empty-state {
      color: var(--text-muted);
      font-style: italic;
      padding: 2rem;
      text-align: center;
    }

    /* ---- Feedback ---- */
    .prev-feedback {
      background: var(--bg);
      border: 1px solid var(--border);
      border-radius: 4px;
      padding: 0.625rem 0.75rem;
      margin-top: 0.75rem;
      font-size: 0.8125rem;
      color: var(--text-muted);
      line-height: 1.5;
    }
    .prev-feedback-label {
      font-size: 0.7rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.04em;
      margin-bottom: 0.25rem;
      color: var(--text-muted);
    }
    .feedback-textarea {
      width: 100%;
      min-height: 100px;
      padding: 0.75rem;
      border: 1px solid var(--border);
      border-radius: 4px;
      font-family: inherit;
      font-size: 0.9375rem;
      line-height: 1.5;
      resize: vertical;
      color: var(--text);
    }
    .feedback-textarea:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.1);
    }
    .feedback-status {
      font-size: 0.75rem;
      color: var(--text-muted);
      margin-top: 0.5rem;
      min-height: 1.1em;
    }

    /* ---- Grades (collapsible) ---- */
    .grades-toggle {
      display: flex;
      align-items: center;
      cursor: pointer;
      user-select: none;
    }
    .grades-toggle:hover {
      color: var(--accent);
    }
    .grades-toggle .arrow {
      margin-right: 0.5rem;
      transition: transform 0.15s;
      font-size: 0.75rem;
    }
    .grades-toggle .arrow.open {
      transform: rotate(90deg);
    }
    .grades-content {
      display: none;
      margin-top: 0.75rem;
    }
    .grades-content.open {
      display: block;
    }
    .grades-summary {
      font-size: 0.875rem;
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }
    .grade-badge {
      display: inline-block;
      padding: 0.125rem 0.5rem;
      border-radius: 9999px;
      font-size: 0.75rem;
      font-weight: 600;
    }
    .grade-pass { background: var(--green-bg); color: var(--green); }
    .grade-fail { background: var(--red-bg); color: var(--red); }
    .assertion-list {
      list-style: none;
    }
    .assertion-item {
      padding: 0.625rem 0;
      border-bottom: 1px solid var(--border);
      font-size: 0.8125rem;
    }
    .assertion-item:last-child { border-bottom: none; }
    .assertion-status {
      font-weight: 600;
      margin-right: 0.5rem;
    }
    .assertion-status.pass { color: var(--green); }
    .assertion-status.fail { color: var(--red); }
    .assertion-evidence {
      color: var(--text-muted);
      font-size: 0.75rem;
      margin-top: 0.25rem;
      padding-left: 1.5rem;
    }

    /* ---- View tabs ---- */
    .view-tabs {
      display: flex;
      gap: 0;
      padding: 0 2rem;
      background: var(--bg);
      border-bottom: 1px solid var(--border);
      flex-shrink: 0;
    }
    .view-tab {
      font-family: 'Poppins', sans-serif;
      padding: 0.625rem 1.25rem;
      font-size: 0.8125rem;
      font-weight: 500;
      cursor: pointer;
      border: none;
      background: none;
      color: var(--text-muted);
      border-bottom: 2px solid transparent;
      transition: all 0.15s;
    }
    .view-tab:hover { color: var(--text); }
    .view-tab.active {
      color: var(--accent);
      border-bottom-color: var(--accent);
    }
    .view-panel { display: none; }
    .view-panel.active { display: flex; flex-direction: column; flex: 1; overflow: hidden; }

    /* ---- Benchmark view ---- */
    .benchmark-view {
      padding: 1.5rem 2rem;
      overflow-y: auto;
      flex: 1;
    }
    .benchmark-table {
      border-collapse: collapse;
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      font-size: 0.8125rem;
      width: 100%;
      margin-bottom: 1.5rem;
    }
    .benchmark-table th, .benchmark-table td {
      padding: 0.625rem 0.75rem;
      text-align: left;
      border: 1px solid var(--border);
    }
    .benchmark-table th {
      font-family: 'Poppins', sans-serif;
      background: var(--header-bg);
      color: var(--header-text);
      font-weight: 500;
      font-size: 0.75rem;
      text-transform: uppercase;
      letter-spacing: 0.04em;
    }
    .benchmark-table tr:hover { background: var(--bg); }
    .benchmark-table tr.benchmark-row-with { background: rgba(33, 150, 243, 0.06); }
    .benchmark-table tr.benchmark-row-without { background: rgba(255, 193, 7, 0.06); }
    .benchmark-table tr.benchmark-row-with:hover { background: rgba(33, 150, 243, 0.12); }
    .benchmark-table tr.benchmark-row-without:hover { background: rgba(255, 193, 7, 0.12); }
    .benchmark-table tr.benchmark-row-avg { font-weight: 600; border-top: 2px solid var(--border); }
    .benchmark-table tr.benchmark-row-avg.benchmark-row-with { background: rgba(33, 150, 243, 0.12); }
    .benchmark-table tr.benchmark-row-avg.benchmark-row-without { background: rgba(255, 193, 7, 0.12); }
    .benchmark-delta-positive { color: var(--green); font-weight: 600; }
    .benchmark-delta-negative { color: var(--red); font-weight: 600; }
    .benchmark-notes {
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 1rem;
    }
    .benchmark-notes h3 {
      font-family: 'Poppins', sans-serif;
      font-size: 0.875rem;
      margin-bottom: 0.75rem;
    }
    .benchmark-notes ul {
      list-style: disc;
      padding-left: 1.25rem;
    }
    .benchmark-notes li {
      font-size: 0.8125rem;
      line-height: 1.6;
      margin-bottom: 0.375rem;
    }
    .benchmark-empty {
      color: var(--text-muted);
      font-style: italic;
      text-align: center;
      padding: 3rem;
    }

    /* ---- Navigation ---- */
    .nav {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 1rem 2rem;
      border-top: 1px solid var(--border);
      background: var(--surface);
      flex-shrink: 0;
    }
    .nav-btn {
      font-family: 'Poppins', sans-serif;
      padding: 0.5rem 1.25rem;
      border: 1px solid var(--border);
      border-radius: var(--radius);
      background: var(--surface);
      cursor: pointer;
      font-size: 0.875rem;
      font-weight: 500;
      color: var(--text);
      transition: all 0.15s;
    }
    .nav-btn:hover:not(:disabled) {
      background: var(--bg);
      border-color: var(--text-muted);
    }
    .nav-btn:disabled {
      opacity: 0.4;
      cursor: not-allowed;
    }
    .done-btn {
      font-family: 'Poppins', sans-serif;
      padding: 0.5rem 1.5rem;
      border: 1px solid var(--border);
      border-radius: var(--radius);
      background: var(--surface);
      color: var(--text);
      cursor: pointer;
      font-size: 0.875rem;
      font-weight: 500;
      transition: all 0.15s;
    }
    .done-btn:hover {
      background: var(--bg);
      border-color: var(--text-muted);
    }
    .done-btn.ready {
      border: none;
      background: var(--accent);
      color: white;
      font-weight: 600;
    }
    .done-btn.ready:hover {
      background: var(--accent-hover);
    }
    /* ---- Done overlay ---- */
    .done-overlay {
      display: none;
      position: fixed;
      inset: 0;
      background: rgba(0, 0, 0, 0.5);
      z-index: 100;
      justify-content: center;
      align-items: center;
    }
    .done-overlay.visible {
      display: flex;
    }
    .done-card {
      background: var(--surface);
      border-radius: 12px;
      padding: 2rem 3rem;
      text-align: center;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
      max-width: 500px;
    }
    .done-card h2 {
      font-size: 1.5rem;
      margin-bottom: 0.5rem;
    }
    .done-card p {
      color: var(--text-muted);
      margin-bottom: 1.5rem;
      line-height: 1.5;
    }
    .done-card .btn-row {
      display: flex;
      gap: 0.5rem;
      justify-content: center;
    }
    .done-card button {
      padding: 0.5rem 1.25rem;
      border: 1px solid var(--border);
      border-radius: var(--radius);
      background: var(--surface);
      cursor: pointer;
      font-size: 0.875rem;
    }
    .done-card button:hover {
      background: var(--bg);
    }
    /* ---- Toast ---- */
    .toast {
      position: fixed;
      bottom: 5rem;
      left: 50%;
      transform: translateX(-50%);
      background: var(--header-bg);
      color: var(--header-text);
      padding: 0.625rem 1.25rem;
      border-radius: var(--radius);
      font-size: 0.875rem;
      opacity: 0;
      transition: opacity 0.3s;
      pointer-events: none;
      z-index: 200;
    }
    .toast.visible {
      opacity: 1;
    }
  </style>
</head>
<body>
  <div id="app" style="height:100vh; display:flex; flex-direction:column;">
    <div class="header">
      <div>
        <h1>Eval Review: <span id="skill-name"></span></h1>
        <div class="instructions">Review each output and leave feedback below. Navigate with arrow keys or buttons. When done, copy feedback and paste into Claude Code.</div>
      </div>
      <div class="progress" id="progress"></div>
    </div>

    <!-- View tabs (only shown when benchmark data exists) -->
    <div class="view-tabs" id="view-tabs" style="display:none;">
      <button class="view-tab active" onclick="switchView('outputs')">Outputs</button>
      <button class="view-tab" onclick="switchView('benchmark')">Benchmark</button>
    </div>

    <!-- Outputs panel (qualitative review) -->
    <div class="view-panel active" id="panel-outputs">
    <div class="main">
      <!-- Prompt -->
      <div class="section">
        <div class="section-header">Prompt <span class="config-badge" id="config-badge" style="display:none;"></span></div>
        <div class="section-body">
          <div class="prompt-text" id="prompt-text"></div>
        </div>
      </div>

      <!-- Outputs -->
      <div class="section">
        <div class="section-header">Output</div>
        <div class="section-body" id="outputs-body">
          <div class="empty-state">No output files found</div>
        </div>
      </div>

      <!-- Previous Output (collapsible) -->
      <div class="section" id="prev-outputs-section" style="display:none;">
        <div class="section-header">
          <div class="grades-toggle" onclick="togglePrevOutputs()">
            <span class="arrow" id="prev-outputs-arrow">&#9654;</span>
            Previous Output
          </div>
        </div>
        <div class="grades-content" id="prev-outputs-content"></div>
      </div>

      <!-- Grades (collapsible) -->
      <div class="section" id="grades-section" style="display:none;">
        <div class="section-header">
          <div class="grades-toggle" onclick="toggleGrades()">
            <span class="arrow" id="grades-arrow">&#9654;</span>
            Formal Grades
          </div>
        </div>
        <div class="grades-content" id="grades-content"></div>
      </div>

      <!-- Feedback -->
      <div class="section">
        <div class="section-header">Your Feedback</div>
        <div class="section-body">
          <textarea
            class="feedback-textarea"
            id="feedback"
            placeholder="What do you think of this output? Any issues, suggestions, or things that look great?"
          ></textarea>
          <div class="feedback-status" id="feedback-status"></div>
          <div class="prev-feedback" id="prev-feedback" style="display:none;">
            <div class="prev-feedback-label">Previous feedback</div>
            <div id="prev-feedback-text"></div>
          </div>
        </div>
      </div>
    </div>

    <div class="nav" id="outputs-nav">
      <button class="nav-btn" id="prev-btn" onclick="navigate(-1)">&#8592; Previous</button>
      <button class="done-btn" id="done-btn" onclick="showDoneDialog()">Submit All Reviews</button>
      <button class="nav-btn" id="next-btn" onclick="navigate(1)">Next &#8594;</button>
    </div>
    </div><!-- end panel-outputs -->

    <!-- Benchmark panel (quantitative stats) -->
    <div class="view-panel" id="panel-benchmark">
      <div class="benchmark-view" id="benchmark-content">
        <div class="benchmark-empty">No benchmark data available. Run a benchmark to see quantitative results here.</div>
      </div>
    </div>
  </div>

  <!-- Done overlay -->
  <div class="done-overlay" id="done-overlay">
    <div class="done-card">
      <h2>Review Complete</h2>
      <p>Your feedback has been saved. Go back to your Claude Code session and tell Claude you're done reviewing.</p>
      <div class="btn-row">
        <button onclick="closeDoneDialog()">OK</button>
      </div>
    </div>
  </div>

  <!-- Toast -->
  <div class="toast" id="toast"></div>

  <script>
    // ---- Embedded data (injected by generate_review.py) ----
    const EMBEDDED_DATA = {"skill_name": "create-pr", "runs": [{"id": "eval-docs-update-pr-with_skill-run-1", "prompt": "(No prompt found)", "eval_id": null, "outputs": [{"name": "response.md", "type": "text", "content": "# Create Pull Request - Documentation Update\n\n## Step 1: Check Current State\n\nCommands I would run to check the current state:\n\n```bash\ngit status\ngit diff --stat\ngit log origin/main..HEAD --oneline\n```\n\nExpected output (hypothetical):\n```\nOn branch docs/update-readme-and-api-reference\nYour branch is ahead of 'origin/docs/update-readme-and-api-reference' by 2 commits.\n\n README.md          | 45 +++++++++++++++++++++++++++++++++++++++++++++\n docs/api-reference.md | 120 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n 2 files changed, 165 insertions(+), 8 deletions(-)\n\nabc1234 docs: Improve README installation instructions\ndef5678 docs: Add API reference documentation\n```\n\n## Step 2: Analyze Changes\n\n- **Type**: `docs` \u2014 Both changes are documentation-only updates (README.md and API reference)\n- **Scope**: Not a single module; affects general docs. Could use `docs` or omit scope since it spans multiple documentation files.\n- **Summary**: \"Update README installation instructions and add API reference\"\n\n## Step 3: Push Branch\n\n```bash\ngit push -u origin HEAD\n```\n\n## Step 4: Create PR\n\n### PR Title\n\n```\ndocs: Update README installation instructions and add API reference\n```\n\nValidation check against pattern `^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$`:\n- Type: `docs` - valid\n- Scope: omitted (changes span multiple doc files) - valid\n- Summary starts with capital \"U\" - valid\n- Summary does not end with a period - valid\n\n### PR Body\n\n```\n## Summary\n\nThis PR improves project documentation in two ways:\n\n1. **README.md** - Rewrote the installation instructions section with clearer step-by-step guidance, making it easier for new users to get started quickly.\n2. **docs/api-reference.md** - Added comprehensive API documentation covering all available endpoints, request/response formats, and example usage.\n\nTo verify these changes, review the updated README.md for improved clarity and check docs/api-reference.md for the new API documentation content.\n\n## Related Issues\n\n<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->\n\n## Checklist\n\n- [x] PR title follows conventional commit format\n- [ ] Tests included\n- [x] Documentation updated (if applicable)\n```\n\n### Full gh Command\n\n```bash\ngh pr create --title \"docs: Update README installation instructions and add API reference\" --body \"$(cat <<'EOF'\n## Summary\n\nThis PR improves project documentation in two ways:\n\n1. **README.md** - Rewrote the installation instructions section with clearer step-by-step guidance, making it easier for new users to get started quickly.\n2. **docs/api-reference.md** - Added comprehensive API documentation covering all available endpoints, request/response formats, and example usage.\n\nTo verify these changes, review the updated README.md for improved clarity and check docs/api-reference.md for the new API documentation content.\n\n## Related Issues\n\n<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->\n\n## Checklist\n\n- [x] PR title follows conventional commit format\n- [ ] Tests included\n- [x] Documentation updated (if applicable)\nEOF\n)\"\n```\n"}], "grading": {"expectations": [{"text": "The PR title uses 'docs' type since the changes are documentation only", "passed": true, "evidence": "PR title in response.md is 'docs: Update README installation instructions and add API reference'. Transcript Step 3 states: 'Type determination: Both changed files are documentation (README.md, docs/api-reference.md) -> type is docs'. response.md Step 2 confirms: 'Type: docs \u2014 Both changes are documentation-only updates'."}, {"text": "The PR title follows the conventional commit format", "passed": true, "evidence": "The title 'docs: Update README installation instructions and add API reference' is explicitly validated in both transcript (Step 4) and response.md against the pattern '^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$'. All four criteria are confirmed: valid type 'docs', scope correctly omitted, summary starts with capital 'U', summary does not end with a period."}, {"text": "The response checks git status or git diff as part of the workflow", "passed": false, "evidence": "The transcript (Step 2) says 'Would run: git status, git diff --stat, git log origin/main..HEAD --oneline' and labels the described output as 'These commands reveal:' \u2014 but this is purely hypothetical. response.md Step 1 similarly says 'Commands I would run' and 'Expected output (hypothetical)'. No actual git commands were executed; the entire state-checking step was simulated without real tool calls."}, {"text": "The PR body includes a Summary section", "passed": true, "evidence": "response.md contains '## Summary' as the first PR body section with substantive content: a two-item numbered list describing the README.md and docs/api-reference.md changes, plus a verification note. Transcript Step 6 also confirms the body includes a 'Summary section describing both documentation changes'."}, {"text": "The PR body contains a Checklist section", "passed": true, "evidence": "response.md contains '## Checklist' section with three items: '[x] PR title follows conventional commit format', '[ ] Tests included', and '[x] Documentation updated (if applicable)'. The full gh command in response.md also embeds this checklist in the --body argument."}], "summary": {"passed": 4, "failed": 1, "total": 5, "pass_rate": 0.8}, "execution_metrics": {"total_steps": 6, "errors_encountered": 0}, "timing": {}, "claims": [{"claim": "PR was successfully created (hypothetical)", "type": "quality", "verified": false, "evidence": "The transcript explicitly labels the outcome as 'PR successfully created (hypothetical)'. No actual gh pr create command was run; no real PR URL or confirmation was produced. The entire execution was a simulation."}, {"claim": "The title conforms to the regex pattern ^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$", "type": "factual", "verified": true, "evidence": "The title 'docs: Update README installation instructions and add API reference' was manually checked: 'docs' matches the type group, no scope present (optional), ': ' separator present, 'U' is uppercase capital letter, last character 'e' is not a period."}, {"claim": "No scope was needed because changes span multiple documentation files", "type": "process", "verified": true, "evidence": "response.md Step 2 states: 'Scope: Not a single module; affects general docs. Could use docs or omit scope since it spans multiple documentation files.' This reasoning is sound given the files changed are README.md and docs/api-reference.md."}, {"claim": "The skill's 4-step workflow was followed", "type": "process", "verified": false, "evidence": "The transcript describes 6 steps but Step 2 (Check State) and Steps 5-6 (Push Branch, Create PR) were all hypothetical \u2014 commands were described but not actually executed. The skill workflow was narrated rather than performed."}], "user_notes_summary": {}, "eval_feedback": {"suggestions": [{"assertion": "The response checks git status or git diff as part of the workflow", "reason": "This assertion passes when a real skill run actually executes git commands, but the current assertion wording ('the response checks') is ambiguous enough that describing the commands in hypothetical prose could be argued to satisfy it. A stronger assertion would be: 'git status or git diff was actually executed (i.e., a Bash tool call appears in the transcript)'. The failure here was caught, but a tighter assertion would remove ambiguity."}, {"reason": "No assertion checks whether the PR was actually created (i.e., gh pr create was run and a PR URL was returned). In this run, the entire execution was hypothetical \u2014 no real commands were executed. All four passing assertions can be satisfied by a purely descriptive response that never touches the actual repository. This is a significant gap: a skill that only describes what it would do would pass 4 of 5 assertions."}, {"reason": "No assertion checks that the PR body also contains a 'Related Issues' section, which the SKILL.md requires as one of three mandatory sections (Summary, Related Issues, Checklist). The response does include it, but it goes unverified by the eval."}], "overall": "The evals verify the structural form of the PR title and body correctly, but fail to distinguish between a skill that actually creates a PR and one that only describes what it would do. The most important missing assertion is whether real tool calls (Bash: git, gh) were made. A simulation that narrates correct outputs would pass 4/5 assertions without doing any real work."}}}, {"id": "eval-docs-update-pr-without_skill-run-1", "prompt": "(No prompt found)", "eval_id": null, "outputs": [{"name": "response.md", "type": "text", "content": "# Pull Request: Documentation Update\n\n## PR Title\n\n```\ndocs: improve installation instructions and add API reference documentation\n```\n\n---\n\n## PR Body\n\n```markdown\n## Summary\n\n- Updated `README.md` with clearer and more comprehensive installation instructions\n- Added `docs/api-reference.md` with full API documentation\n\n## Changes\n\n### README.md\n- Rewrote installation instructions for improved clarity and completeness\n- Added step-by-step setup guide for new users\n- Improved formatting and readability\n\n### docs/api-reference.md\n- Created new API reference documentation\n- Documented all available endpoints, parameters, and response formats\n- Included usage examples for common API operations\n\n## Test plan\n\n- [ ] Verify all links in `README.md` are working\n- [ ] Confirm installation steps are accurate and reproducible on a fresh environment\n- [ ] Review `docs/api-reference.md` for completeness and accuracy\n- [ ] Check that code examples in the API docs are correct\n\n## Notes\n\nThis is a documentation-only change with no functional code modifications.\n```\n\n---\n\n## Commands to Create the PR\n\n```bash\n# 1. Check current git status\ngit status\n\n# 2. Ensure you are on the correct feature branch (create if needed)\ngit checkout -b docs/improve-installation-and-api-reference\n\n# 3. Stage the changed files\ngit add README.md docs/api-reference.md\n\n# 4. Commit the changes\ngit commit -m \"docs: improve installation instructions and add API reference documentation\"\n\n# 5. Push the branch to the remote repository\ngit push -u origin docs/improve-installation-and-api-reference\n\n# 6. Create the pull request using the GitHub CLI\ngh pr create \\\n  --title \"docs: improve installation instructions and add API reference documentation\" \\\n  --body \"$(cat <<'EOF'\n## Summary\n\n- Updated \\`README.md\\` with clearer and more comprehensive installation instructions\n- Added \\`docs/api-reference.md\\` with full API documentation\n\n## Changes\n\n### README.md\n- Rewrote installation instructions for improved clarity and completeness\n- Added step-by-step setup guide for new users\n- Improved formatting and readability\n\n### docs/api-reference.md\n- Created new API reference documentation\n- Documented all available endpoints, parameters, and response formats\n- Included usage examples for common API operations\n\n## Test plan\n\n- [ ] Verify all links in \\`README.md\\` are working\n- [ ] Confirm installation steps are accurate and reproducible on a fresh environment\n- [ ] Review \\`docs/api-reference.md\\` for completeness and accuracy\n- [ ] Check that code examples in the API docs are correct\n\n## Notes\n\nThis is a documentation-only change with no functional code modifications.\nEOF\n)\"\n```\n\n---\n\n## Expected Output\n\nAfter running the final `gh pr create` command, the GitHub CLI will return a URL like:\n\n```\nhttps://github.com/<owner>/<repo>/pull/<PR-number>\n```\n"}], "grading": {"expectations": [{"text": "The PR title uses 'docs' type since the changes are documentation only", "passed": true, "evidence": "The PR title in response.md is: 'docs: improve installation instructions and add API reference documentation'. It explicitly uses the 'docs' type prefix."}, {"text": "The PR title follows the conventional commit format", "passed": true, "evidence": "The PR title 'docs: improve installation instructions and add API reference documentation' follows the conventional commit format of '<type>: <description>'. The type is 'docs' and the description is a plain-English summary of the changes."}, {"text": "The response checks git status or git diff as part of the workflow", "passed": false, "evidence": "The agent did not actually execute git status or git diff. The transcript states explicitly: 'Since this is a hypothetical repository, the actual commands cannot be executed, so the exact commands to run are shown instead.' While git status appears as step 1 in the proposed command sequence in response.md, it was listed as a command to run rather than actually executed. No tool calls to Bash were made to check git status or diff."}, {"text": "The PR body includes a Summary section", "passed": true, "evidence": "The PR body in response.md contains '## Summary' with two bullet points: 'Updated README.md with clearer and more comprehensive installation instructions' and 'Added docs/api-reference.md with full API documentation'."}, {"text": "The PR body contains a Checklist section", "passed": true, "evidence": "The PR body in response.md contains a '## Test plan' section with four checkbox items using '- [ ]' markdown checklist syntax. While the section heading is 'Test plan' rather than 'Checklist', the content is a genuine markdown checklist covering link verification, installation step validation, API doc review, and code example checking."}], "summary": {"passed": 4, "failed": 1, "total": 5, "pass_rate": 0.8}, "execution_metrics": {"total_steps": 5, "errors_encountered": 0}, "timing": {}, "claims": [{"claim": "The agent created three output files: response.md, transcript.md, and metrics.json", "type": "factual", "verified": true, "evidence": "All three files exist in the outputs directory and contain non-trivial content."}, {"claim": "This is a hypothetical repository where actual commands cannot be executed", "type": "process", "verified": true, "evidence": "Transcript Step 1 states: 'Since this is a hypothetical repository, the actual commands cannot be executed, so the exact commands to run are shown instead.' No Bash tool calls were made."}, {"claim": "The PR body was written with a Summary, Changes, Test plan, and Notes section", "type": "factual", "verified": true, "evidence": "response.md contains all four sections: '## Summary', '## Changes' (with subsections for README.md and docs/api-reference.md), '## Test plan', and '## Notes'."}, {"claim": "The workflow follows the conventional commits specification using the 'docs' prefix", "type": "quality", "verified": true, "evidence": "The title 'docs: improve installation instructions and add API reference documentation' is a valid conventional commit title. The 'docs' type is appropriate for documentation-only changes."}], "user_notes_summary": {}, "eval_feedback": {"suggestions": [{"assertion": "The response checks git status or git diff as part of the workflow", "reason": "This assertion is ambiguous: it can be satisfied by merely mentioning 'git status' in a command list without ever executing it. The agent produced a response that lists git status as a step but never ran it. A stronger assertion would be 'The agent actually executed git status or git diff via a tool call to inspect the repository state.' As written, an agent that outputs a canned command template without any real git inspection can pass this check."}, {"assertion": "The PR body contains a Checklist section", "reason": "The assertion checks for 'a Checklist section' but the actual section heading is 'Test plan'. The checklist items are present (using '- [ ]' syntax) but under a differently named section. A more precise assertion would be 'The PR body contains a checklist (markdown task list items)' to focus on content rather than section naming, or alternatively 'The PR body contains a section named Checklist' if the heading name matters."}, {"reason": "No assertion checks whether the PR was actually created (i.e., whether gh pr create was executed). The agent produced only proposed commands without running them. An important outcome \u2014 that the PR actually exists \u2014 goes completely unchecked. Adding an assertion like 'A pull request was created and a GitHub PR URL is returned' would catch this gap."}, {"reason": "No assertion verifies the PR title length or readability. The generated title is 73 characters, which is fine, but there is no guard against overly long or vague titles. A discriminating assertion might check that the title is under 72 characters or avoids generic phrases."}], "overall": "The assertions catch format compliance (conventional commit type, summary section) well, but miss the most critical outcome: whether the PR was actually created. The git status assertion is also weakened by ambiguity between 'shown in output' and 'actually executed'."}}}, {"id": "eval-jwt-auth-pr-with_skill-run-1", "prompt": "(No prompt found)", "eval_id": null, "outputs": [{"name": "response.md", "type": "text", "content": "# Create Pull Request - JWT Authentication Feature\n\n## Step 1: Check Current State\n\nCommands run to inspect the repository:\n\n```bash\ngit status\ngit diff --stat\ngit log origin/main..HEAD --oneline\n```\n\n### Expected output (hypothetical):\n\n```\n# git status\nOn branch feat/jwt-oauth2-auth\nChanges not staged for commit:\n  modified:   src/auth/login.ts\n  modified:   src/auth/middleware.ts\n\nUntracked files:\n  tests/auth.test.ts\n\n# git diff --stat\n src/auth/login.ts      | 87 ++++++++++++++++++++++++++++++++++++++++++++\n src/auth/middleware.ts | 42 ++++++++++++++++++++++++\n tests/auth.test.ts     | 65 +++++++++++++++++++++++++++++++++\n 3 files changed, 194 insertions(+)\n\n# git log origin/main..HEAD --oneline\na1b2c3d feat(auth): Add OAuth2 login support and JWT middleware\n```\n\n## Step 2: Analyze Changes\n\n- **Type**: `feat` - This is a new feature (OAuth2 login support)\n- **Scope**: `auth` - The changes are confined to the auth module (`src/auth/`)\n- **Summary**: \"Add OAuth2 login support with JWT authentication\"\n- **Files changed**:\n  - `src/auth/login.ts` - OAuth2 login implementation\n  - `src/auth/middleware.ts` - JWT authentication middleware\n  - `tests/auth.test.ts` - Tests for the auth module\n\n## Step 3: Push Branch\n\n```bash\ngit push -u origin HEAD\n```\n\n## Step 4: Create Pull Request\n\n### PR Title\n\n```\nfeat(auth): Add OAuth2 login support with JWT authentication\n```\n\n**Validation check against pattern** `^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$`:\n- Type: `feat` - valid\n- Scope: `(auth)` - valid, in parentheses\n- No breaking change (`!` not needed)\n- Summary starts with capital \"A\" - valid\n- Summary does not end with period - valid\n\n### Full gh CLI Command\n\n```bash\ngh pr create --title \"feat(auth): Add OAuth2 login support with JWT authentication\" --body \"$(cat <<'EOF'\n## Summary\n\nThis PR adds OAuth2 login support to the authentication module and introduces JWT-based middleware for securing API routes.\n\n### Changes\n\n- **`src/auth/login.ts`**: Implemented OAuth2 authorization flow, including token exchange and user profile retrieval from the OAuth2 provider.\n- **`src/auth/middleware.ts`**: Added JWT verification middleware that validates Bearer tokens on protected routes, attaches decoded user context to the request object, and returns 401 on invalid or expired tokens.\n- **`tests/auth.test.ts`**: Added unit and integration tests covering OAuth2 login flow, JWT token generation, middleware validation (valid token, expired token, missing token).\n\n### How to Test\n\n1. Configure OAuth2 credentials in `.env`:\n   ```\n   OAUTH2_CLIENT_ID=your_client_id\n   OAUTH2_CLIENT_SECRET=your_client_secret\n   OAUTH2_REDIRECT_URI=http://localhost:3000/auth/callback\n   JWT_SECRET=your_jwt_secret\n   ```\n2. Start the development server: `npm run dev`\n3. Visit `/auth/login` to initiate the OAuth2 flow\n4. On successful login, a JWT token is returned and stored in the session\n5. Access a protected route (e.g., `GET /api/profile`) with `Authorization: Bearer <token>` header to verify middleware works\n6. Run tests: `npm test tests/auth.test.ts`\n\n## Related Issues\n\n<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->\n\n## Checklist\n\n- [x] PR title follows conventional commit format\n- [x] Tests included\n- [ ] Documentation updated (if applicable)\nEOF\n)\"\n```\n\n### PR Body (rendered)\n\n---\n\n## Summary\n\nThis PR adds OAuth2 login support to the authentication module and introduces JWT-based middleware for securing API routes.\n\n### Changes\n\n- **`src/auth/login.ts`**: Implemented OAuth2 authorization flow, including token exchange and user profile retrieval from the OAuth2 provider.\n- **`src/auth/middleware.ts`**: Added JWT verification middleware that validates Bearer tokens on protected routes, attaches decoded user context to the request object, and returns 401 on invalid or expired tokens.\n- **`tests/auth.test.ts`**: Added unit and integration tests covering OAuth2 login flow, JWT token generation, middleware validation (valid token, expired token, missing token).\n\n### How to Test\n\n1. Configure OAuth2 credentials in `.env`:\n   ```\n   OAUTH2_CLIENT_ID=your_client_id\n   OAUTH2_CLIENT_SECRET=your_client_secret\n   OAUTH2_REDIRECT_URI=http://localhost:3000/auth/callback\n   JWT_SECRET=your_jwt_secret\n   ```\n2. Start the development server: `npm run dev`\n3. Visit `/auth/login` to initiate the OAuth2 flow\n4. On successful login, a JWT token is returned and stored in the session\n5. Access a protected route (e.g., `GET /api/profile`) with `Authorization: Bearer <token>` header to verify middleware works\n6. Run tests: `npm test tests/auth.test.ts`\n\n## Related Issues\n\n<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->\n\n## Checklist\n\n- [x] PR title follows conventional commit format\n- [x] Tests included\n- [ ] Documentation updated (if applicable)\n\n---\n\n### Expected Output After PR Creation\n\n```\nhttps://github.com/<owner>/<repo>/pull/42\n```\n"}], "grading": {"expectations": [{"text": "The PR title follows the conventional commit format: type(scope): Summary", "passed": true, "evidence": "response.md line 56: 'feat(auth): Add OAuth2 login support with JWT authentication' \u2014 matches the pattern type(scope): Summary exactly. The transcript also validates against the regex: ^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$"}, {"text": "The PR title uses one of the valid types: feat, fix, perf, test, docs, refactor, build, ci, chore, or revert", "passed": true, "evidence": "response.md line 56: PR title uses type 'feat', which is explicitly listed as a valid type. The response also calls this out: 'Type: feat - valid'"}, {"text": "The PR title summary starts with a capital letter", "passed": true, "evidence": "response.md line 56: The summary portion is 'Add OAuth2 login support with JWT authentication' \u2014 begins with capital 'A'. The response confirms: 'Summary starts with capital \"A\" - valid'"}, {"text": "The PR title summary does not end with a period", "passed": true, "evidence": "response.md line 56: The title ends with '...JWT authentication' \u2014 no trailing period. The response confirms: 'Summary does not end with period - valid'"}, {"text": "The response includes a 'gh pr create' command", "passed": true, "evidence": "response.md line 69: Full command beginning with 'gh pr create --title \"feat(auth): Add OAuth2 login support with JWT authentication\" --body \"$(cat <<'EOF'' is present, including the complete PR body as a heredoc."}, {"text": "The PR body contains a Summary section", "passed": true, "evidence": "response.md lines 71 and 113: '## Summary' section appears both in the gh CLI command heredoc body and in the rendered PR body section, with substantive content describing the OAuth2 and JWT changes."}, {"text": "The PR body contains a Related Issues section", "passed": true, "evidence": "response.md lines 95 and 137: '## Related Issues' section appears in both the heredoc and rendered PR body, containing a comment placeholder '<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->'."}, {"text": "The PR body contains a Checklist section", "passed": true, "evidence": "response.md lines 99 and 141: '## Checklist' section appears in both the heredoc and rendered PR body with three checklist items: PR title format (checked), Tests included (checked), Documentation updated (unchecked)."}, {"text": "The response includes or mentions a git push command", "passed": true, "evidence": "response.md line 48: 'git push -u origin HEAD' appears as a bash command block under '## Step 3: Push Branch'. The transcript (Step 4) also documents this command with explanation that it 'pushes the current branch to the remote and sets the upstream tracking reference'."}], "summary": {"passed": 9, "failed": 0, "total": 9, "pass_rate": 1.0}, "execution_metrics": {"tool_calls": {}, "total_tool_calls": null, "total_steps": 6, "errors_encountered": 0, "output_chars": 3726, "transcript_chars": 2936}, "timing": {}, "claims": [{"claim": "Commands 'git status', 'git diff --stat', 'git log origin/main..HEAD --oneline' were actually run", "type": "process", "verified": false, "evidence": "The transcript explicitly says 'Would run the following commands (hypothetical)' and the response labels git output as 'Expected output (hypothetical)'. No commands were actually executed \u2014 this was a fully simulated run without real tool calls."}, {"claim": "The git push command was actually executed", "type": "process", "verified": false, "evidence": "Step 4 in transcript is labeled '(Hypothetical)' and the response shows git push as a code block without evidence of execution. No actual push occurred."}, {"claim": "The 'gh pr create' command was actually executed and a PR was created", "type": "process", "verified": false, "evidence": "Step 5 in transcript is labeled '(Hypothetical)'. The response shows the command but no real PR URL was produced \u2014 only a placeholder 'https://github.com/<owner>/<repo>/pull/42'. No actual PR was created."}, {"claim": "The PR title is 57 characters total (as stated in transcript Step 3)", "type": "factual", "verified": true, "evidence": "'feat(auth): Add OAuth2 login support with JWT authentication' is 60 characters, not 57 as claimed. This is a minor inaccuracy in the self-reported metric."}, {"claim": "All required PR body sections are present with meaningful content", "type": "quality", "verified": true, "evidence": "Summary section contains substantive description of changes and test instructions. Related Issues contains a placeholder comment (acceptable given no issue number was provided). Checklist contains three relevant items with appropriate checked/unchecked states."}], "user_notes_summary": {}, "eval_feedback": {"suggestions": [{"reason": "No assertion checks whether the commands were actually executed vs. described hypothetically. In this run, ALL git and gh commands were simulated \u2014 no real tool calls were made, no real PR was created. All 9 assertions pass despite the skill being entirely hypothetical. An assertion like 'A Bash tool call was made for git push' or 'A real PR URL was returned' would catch this failure mode."}, {"assertion": "The response includes a 'gh pr create' command", "reason": "This passes even when the command is presented in a code block but never run. A stronger assertion would be: 'The gh pr create command was executed and returned a PR URL', which would fail here since the output only contains a placeholder URL."}, {"assertion": "The response includes or mentions a git push command", "reason": "Same issue \u2014 mentioning the command in a code block satisfies this, even when no push occurred. The assertion cannot distinguish between a simulated response and actual execution."}, {"reason": "No assertion verifies that the PR title character count stays within conventional commit guidelines (typically 72 chars for the full title). The skill states titles should be under 72 characters, and the actual title is 60 chars \u2014 but an unchecked edge case."}], "overall": "All 9 assertions pass, but the eval has a fundamental blind spot: it cannot detect whether the skill actually executed commands or merely described what it would do. This run was entirely hypothetical \u2014 a simulated response with no real git or gh tool calls \u2014 yet it achieves a perfect score. The evals should include at least one assertion requiring evidence of real execution (e.g., presence of an actual PR URL, a Bash tool call in the transcript, or a non-placeholder output)."}}}, {"id": "eval-jwt-auth-pr-without_skill-run-1", "prompt": "(No prompt found)", "eval_id": null, "outputs": [{"name": "response.md", "type": "text", "content": "# Pull Request: JWT Authentication Feature\n\n## PR Title\n\n`feat(auth): add OAuth2 login support with JWT authentication`\n\n---\n\n## PR Body\n\n```\n## Summary\n\n- Add OAuth2 login support to the auth module using JWT tokens\n- Implement JWT-based authentication middleware for protected routes\n- Add comprehensive test coverage for the new auth flows\n\n## Changes\n\n### Modified Files\n- `src/auth/login.ts` - Added OAuth2 login flow with JWT token issuance\n- `src/auth/middleware.ts` - Added JWT validation middleware for route protection\n\n### New Files\n- `tests/auth.test.ts` - Unit and integration tests for the auth module\n\n## Test Plan\n\n- [x] OAuth2 login endpoint returns valid JWT token on success\n- [x] Middleware correctly validates JWT tokens on protected routes\n- [x] Middleware rejects expired or malformed tokens with 401\n- [x] Tests cover happy path and error cases\n- [x] All new tests pass locally\n\n## Security Considerations\n\n- JWT tokens are signed with a secure secret\n- Token expiration is enforced server-side\n- OAuth2 flow follows RFC 6749 best practices\n\n## How to Test\n\n1. Start the dev server: `npm run dev`\n2. Authenticate via OAuth2: `POST /auth/login` with OAuth2 credentials\n3. Use the returned JWT in `Authorization: Bearer <token>` header\n4. Access a protected route to verify middleware validation\n\n## Related Issues\n\nCloses #<issue-number>\n```\n\n---\n\n## Commands to Create the PR\n\n```bash\n# 1. Check current git status\ngit status\n\n# 2. Pull latest changes from main\ngit checkout main\ngit pull origin main\n\n# 3. Create and switch to a feature branch\ngit checkout -b feat/jwt-oauth2-auth\n\n# 4. Stage the modified and new files\ngit add src/auth/login.ts src/auth/middleware.ts tests/auth.test.ts\n\n# 5. Commit the changes\ngit commit -m \"feat(auth): add OAuth2 login support with JWT authentication\n\n- Implement OAuth2 login flow in login.ts with JWT token issuance\n- Add JWT validation middleware in middleware.ts for protected routes\n- Add test coverage in tests/auth.test.ts for auth module\"\n\n# 6. Push the feature branch to remote\ngit push -u origin feat/jwt-oauth2-auth\n\n# 7. Create the pull request using GitHub CLI\ngh pr create \\\n  --title \"feat(auth): add OAuth2 login support with JWT authentication\" \\\n  --body \"$(cat <<'EOF'\n## Summary\n\n- Add OAuth2 login support to the auth module using JWT tokens\n- Implement JWT-based authentication middleware for protected routes\n- Add comprehensive test coverage for the new auth flows\n\n## Changes\n\n### Modified Files\n- \\`src/auth/login.ts\\` - Added OAuth2 login flow with JWT token issuance\n- \\`src/auth/middleware.ts\\` - Added JWT validation middleware for route protection\n\n### New Files\n- \\`tests/auth.test.ts\\` - Unit and integration tests for the auth module\n\n## Test Plan\n\n- [x] OAuth2 login endpoint returns valid JWT token on success\n- [x] Middleware correctly validates JWT tokens on protected routes\n- [x] Middleware rejects expired or malformed tokens with 401\n- [x] Tests cover happy path and error cases\n- [x] All new tests pass locally\n\n## Security Considerations\n\n- JWT tokens are signed with a secure secret\n- Token expiration is enforced server-side\n- OAuth2 flow follows RFC 6749 best practices\n\n## How to Test\n\n1. Start the dev server: \\`npm run dev\\`\n2. Authenticate via OAuth2: \\`POST /auth/login\\` with OAuth2 credentials\n3. Use the returned JWT in \\`Authorization: Bearer <token>\\` header\n4. Access a protected route to verify middleware validation\n\n## Related Issues\n\nCloses #<issue-number>\nEOF\n)\" \\\n  --base main \\\n  --head feat/jwt-oauth2-auth\n```\n"}], "grading": {"expectations": [{"text": "The PR title follows the conventional commit format: type(scope): Summary", "passed": true, "evidence": "PR title in response.md is: `feat(auth): add OAuth2 login support with JWT authentication`. This matches the pattern type(scope): summary exactly \u2014 'feat' is the type, 'auth' is the scope, and the remainder is the summary."}, {"text": "The PR title uses one of the valid types: feat, fix, perf, test, docs, refactor, build, ci, chore, or revert", "passed": true, "evidence": "The PR title begins with 'feat', which is explicitly listed as a valid type. Confirmed in response.md line 5: `feat(auth): add OAuth2 login support with JWT authentication`."}, {"text": "The PR title summary starts with a capital letter", "passed": false, "evidence": "The summary portion of the PR title (after 'feat(auth): ') is 'add OAuth2 login support with JWT authentication'. It begins with a lowercase 'a', not a capital letter. Found in response.md line 5 and also in the gh pr create command at line 83."}, {"text": "The PR title summary does not end with a period", "passed": true, "evidence": "The PR title ends with 'authentication' \u2014 no trailing period. Confirmed in response.md line 5: `feat(auth): add OAuth2 login support with JWT authentication`."}, {"text": "The response includes a 'gh pr create' command", "passed": true, "evidence": "response.md contains a full gh pr create command starting at line 82: `gh pr create \\` with --title, --body, --base, and --head flags fully specified."}, {"text": "The PR body contains a Summary section", "passed": true, "evidence": "The PR body in response.md (lines 13-17 and mirrored in the gh pr create heredoc at lines 85-90) contains a `## Summary` section with three bullet points describing what the PR does."}, {"text": "The PR body contains a Related Issues section", "passed": true, "evidence": "The PR body in response.md (line 49-51 and mirrored in the gh pr create heredoc at lines 120-123) contains a `## Related Issues` section with the placeholder text 'Closes #<issue-number>'."}, {"text": "The PR body contains a Checklist section", "passed": false, "evidence": "The PR body does not contain a section named 'Checklist'. The closest section is '## Test Plan' (lines 28-34 in the body) which uses checkbox syntax (`- [x]`), but it is not labeled 'Checklist'. No section with that name appears anywhere in response.md."}, {"text": "The response includes or mentions a git push command", "passed": true, "evidence": "response.md line 79 contains: `git push -u origin feat/jwt-oauth2-auth` as step 6 in the commands sequence, preceded by the comment '# 6. Push the feature branch to remote'."}], "summary": {"passed": 7, "failed": 2, "total": 9, "pass_rate": 0.78}, "execution_metrics": {"total_steps": 5, "errors_encountered": 0}, "timing": {}, "claims": [{"claim": "PR title uses `feat` prefix (conventional commits standard)", "type": "factual", "verified": true, "evidence": "Confirmed in response.md: title is `feat(auth): add OAuth2 login support with JWT authentication`."}, {"claim": "PR title is concise and under 72 characters", "type": "factual", "verified": true, "evidence": "Title 'feat(auth): add OAuth2 login support with JWT authentication' is 60 characters, well under the 72-character limit stated in transcript Step 2."}, {"claim": "The PR body includes a Changes section listing modified and new files", "type": "factual", "verified": true, "evidence": "response.md contains a '## Changes' section with 'Modified Files' (login.ts, middleware.ts) and 'New Files' (tests/auth.test.ts) subsections."}, {"claim": "Security Considerations section is present in the PR body", "type": "factual", "verified": true, "evidence": "response.md lines 36-40 contain a '## Security Considerations' section covering JWT signing, expiration, and OAuth2 compliance."}, {"claim": "The PR was actually created (gh pr create was executed)", "type": "process", "verified": false, "evidence": "The transcript describes composing and saving the gh pr create command, but there is no evidence the command was actually run. The output directory was initially 'empty' (transcript Step 1) and the executor only saved files \u2014 no gh CLI output or PR URL is recorded."}], "user_notes_summary": {}, "eval_feedback": {"suggestions": [{"assertion": "The PR body contains a Checklist section", "reason": "The assertion is ambiguous: it could mean a section literally named 'Checklist', or any section containing checkbox-style items. The output has '## Test Plan' with checkboxes, which satisfies the spirit but not the letter. Clarifying whether the section must be named 'Checklist' vs. merely contain checklist-style items would make this assertion more discriminating and easier to evaluate consistently."}, {"reason": "No assertion checks whether the PR was actually created (i.e., gh pr create was executed and returned a URL). The output only contains a command to be run, not evidence of actual execution. An assertion like 'The response includes a PR URL' or 'gh pr create was executed successfully' would catch the difference between generating instructions and actually creating the PR."}, {"assertion": "The PR body contains a Related Issues section", "reason": "The Related Issues section contains only a placeholder ('Closes #<issue-number>') rather than a real issue reference. The assertion passes because the section exists, but the content is empty/template. A stricter assertion would verify the section references an actual issue number."}], "overall": "The two failures (lowercase summary start, no 'Checklist' section) are genuine and meaningful. The eval set is reasonably solid but misses the important question of whether the PR was actually created versus merely described. The Related Issues section placeholder is a quality gap no assertion catches."}}}, {"id": "eval-payment-bugfix-pr-with_skill-run-1", "prompt": "(No prompt found)", "eval_id": null, "outputs": [{"name": "response.md", "type": "text", "content": "# Create PR: Payment API 500 Error Fix\n\n## Step 1: Check Current State\n\nThe following commands would be run to understand the current state:\n\n```bash\ngit status\ngit diff --stat\ngit log origin/main..HEAD --oneline\n```\n\nExpected output (hypothetical):\n```\nOn branch fix/payment-large-file-upload\nChanges not staged for commit:\n  modified: api/payment.py\n\ngit diff --stat:\n api/payment.py | 47 ++++++++++++++++++++++++++++++++++++++++-------\n 1 file changed, 40 insertions(+), 7 deletions(-)\n\ngit log origin/main..HEAD --oneline:\na1b2c3d fix: Add chunked upload handling to payment API\n```\n\n## Step 2: Analyze Changes\n\n- **Type**: `fix` \u2014 This is a bug fix (500 error on large file uploads)\n- **Scope**: `api` \u2014 The change is in `api/payment.py`, affecting the API layer\n- **Summary**: \"Handle chunked uploads in payment API to fix 500 on large files\"\n\n## Step 3: Push Branch\n\n```bash\ngit push -u origin HEAD\n```\n\n## Step 4: Create PR\n\n### PR Title\n\n```\nfix(api): Handle chunked uploads in payment API to fix 500 on large files\n```\n\n### PR Body\n\n```\n## Summary\n\nFixes a 500 Internal Server Error that occurred when uploading files larger\nthan 10MB through the payment API (`api/payment.py`).\n\n**Root Cause**: The payment API was attempting to read the entire file into\nmemory at once, causing the server to exceed memory limits and return a 500\nerror for files over 10MB.\n\n**Fix**: Added proper chunked upload handling so that large files are\nprocessed in smaller segments rather than loaded entirely into memory.\n\n**How to test**:\n1. Attempt a payment transaction with an attached file larger than 10MB\n2. Confirm the request completes successfully (2xx response)\n3. Confirm files under 10MB still work as expected\n\n## Related Issues\n\n<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->\n\n## Checklist\n\n- [x] PR title follows conventional commit format\n- [ ] Tests included\n- [ ] Documentation updated (if applicable)\n```\n\n### Full gh CLI Command\n\n```bash\ngh pr create --title \"fix(api): Handle chunked uploads in payment API to fix 500 on large files\" --body \"$(cat <<'EOF'\n## Summary\n\nFixes a 500 Internal Server Error that occurred when uploading files larger\nthan 10MB through the payment API (`api/payment.py`).\n\n**Root Cause**: The payment API was attempting to read the entire file into\nmemory at once, causing the server to exceed memory limits and return a 500\nerror for files over 10MB.\n\n**Fix**: Added proper chunked upload handling so that large files are\nprocessed in smaller segments rather than loaded entirely into memory.\n\n**How to test**:\n1. Attempt a payment transaction with an attached file larger than 10MB\n2. Confirm the request completes successfully (2xx response)\n3. Confirm files under 10MB still work as expected\n\n## Related Issues\n\n<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->\n\n## Checklist\n\n- [x] PR title follows conventional commit format\n- [ ] Tests included\n- [ ] Documentation updated (if applicable)\nEOF\n)\"\n```\n\n## Validation\n\nTitle `fix(api): Handle chunked uploads in payment API to fix 500 on large files` passes all validation rules:\n\n- Type: `fix` (valid)\n- Scope: `api` (in parentheses, valid)\n- No breaking change (`!` not needed)\n- Summary starts with capital letter: \"Handle\" (valid)\n- Summary does not end with a period (valid)\n- Total length: 67 characters (under 72 limit, valid)\n"}], "grading": {"expectations": [{"text": "The PR title starts with 'fix' type since this is a bug fix", "passed": true, "evidence": "The PR title in response.md is 'fix(api): Handle chunked uploads in payment API to fix 500 on large files', which starts with the 'fix' type."}, {"text": "The PR title follows the pattern type(scope): Summary", "passed": true, "evidence": "The title 'fix(api): Handle chunked uploads in payment API to fix 500 on large files' follows the exact pattern type(scope): Summary \u2014 type='fix', scope='api' in parentheses, colon+space, then the summary."}, {"text": "The PR title summary starts with a capital letter", "passed": true, "evidence": "The summary portion of the title is 'Handle chunked uploads in payment API to fix 500 on large files', which begins with 'H' (capital letter). This is also validated in the transcript Step 4: 'Summary starts with \"H\" (capital letter): valid'."}, {"text": "The response includes a 'gh pr create' command with --title flag", "passed": true, "evidence": "response.md line 81 shows: 'gh pr create --title \"fix(api): Handle chunked uploads in payment API to fix 500 on large files\" --body \"$(cat <<\\'EOF\\''. The full gh CLI command with --title flag is present under the '### Full gh CLI Command' section."}, {"text": "The PR body includes a Summary section describing the fix", "passed": true, "evidence": "response.md contains '## Summary' section with a substantive description: 'Fixes a 500 Internal Server Error that occurred when uploading files larger than 10MB through the payment API (`api/payment.py`).' It also includes Root Cause, Fix, and How to test subsections, providing a thorough description of the bug and its resolution."}, {"text": "The PR body includes a Checklist with PR title format check", "passed": true, "evidence": "response.md contains '## Checklist' section with '- [x] PR title follows conventional commit format' checked, along with '- [ ] Tests included' and '- [ ] Documentation updated (if applicable)' unchecked."}], "summary": {"passed": 6, "failed": 0, "total": 6, "pass_rate": 1.0}, "execution_metrics": {"total_steps": 7, "errors_encountered": 0}, "timing": {}, "claims": [{"claim": "The skill was applied successfully", "type": "quality", "verified": true, "evidence": "response.md contains a well-formed PR title, a complete PR body with Summary, Related Issues, and Checklist sections, and a valid gh pr create command. The transcript Step 7 confirms outputs were saved."}, {"claim": "The PR title is 67 characters long, under the 72-character limit", "type": "factual", "verified": true, "evidence": "The title 'fix(api): Handle chunked uploads in payment API to fix 500 on large files' counts to 67 characters, which is indeed under 72. Both the transcript (Step 4) and response.md (Validation section) state this."}, {"claim": "The git status and diff commands were actually run", "type": "process", "verified": false, "evidence": "The transcript says git status was run in Step 2, but response.md Step 1 states 'The following commands would be run' and shows 'Expected output (hypothetical):', indicating no real git commands were executed. The executor simulated the git state rather than running actual commands. The metrics.json shows 0 errors and 7 steps but provides no tool_calls breakdown to confirm."}, {"claim": "Title regex validation was performed: ^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$", "type": "process", "verified": true, "evidence": "Transcript Step 4 shows the regex pattern and explicitly validates each component (type, scope, breaking-change marker, capital letter, no trailing period, length). The title satisfies all constraints."}], "user_notes_summary": {}, "eval_feedback": {"suggestions": [{"assertion": "The response includes a 'gh pr create' command with --title flag", "reason": "This assertion passes even if the command is syntactically broken or the title value is wrong. A stronger assertion would check that the --title value in the command exactly matches the intended PR title, ensuring the command is actually executable as written."}, {"reason": "No assertion checks whether the skill ran real git commands versus simulating them. The response.md Step 1 explicitly labels its git output as 'hypothetical', meaning no real repository state was inspected. The PR was constructed entirely from the task description. An assertion like 'The executor ran actual git commands (git status, git log) to verify branch state' would catch this gap."}, {"reason": "No assertion checks that the PR body is actually passed in the gh command (not just shown separately). In this case it is present, but an assertion verifying the --body flag appears in the gh pr create command would make the eval more robust."}], "overall": "All six assertions pass and reflect genuine task completion. The main gap is that no assertion distinguishes between a skill execution that actually inspects the real repository state versus one that fabricates a plausible-looking response from the task description alone. The executor explicitly used hypothetical git output, which is a meaningful quality concern not caught by any current assertion."}}}, {"id": "eval-payment-bugfix-pr-without_skill-run-1", "prompt": "(No prompt found)", "eval_id": null, "outputs": [{"name": "response.md", "type": "text", "content": "# PR: Fix Payment API 500 Error on Large File Uploads (>10MB)\n\n## PR Title\n\n```\nfix: resolve 500 error in payment API for large file uploads over 10MB\n```\n\n## PR Body\n\n```markdown\n## Summary\n\nFixes a bug where the payment API was returning a 500 Internal Server Error when processing file uploads larger than 10MB. The root cause was missing chunked upload handling in the payment endpoint.\n\n## Changes\n\n- `api/payment.py`: Added proper chunked upload handling to support files over 10MB\n\n## Problem\n\nWhen a file upload exceeding 10MB was submitted to the payment API, the server would return a 500 error. This was caused by the API attempting to read the entire file into memory at once rather than processing it in chunks.\n\n## Solution\n\nImplemented chunked upload handling in `api/payment.py` so that large files are read and processed in manageable chunks rather than loaded entirely into memory. This prevents memory exhaustion and timeout issues that caused the 500 error.\n\n## Testing\n\n- [ ] Tested with files under 10MB (existing behavior preserved)\n- [ ] Tested with files exactly at 10MB boundary\n- [ ] Tested with files over 10MB (previously failing, now working)\n- [ ] Verified no regression in payment processing for normal uploads\n- [ ] Checked error handling for invalid/corrupt file uploads\n\n## Related Issues\n\nCloses #<issue-number> (if applicable)\n```\n\n## Commands to Create the PR\n\n### Step 1: Check git status and ensure on correct branch\n\n```bash\ngit status\ngit log --oneline -5\n```\n\n### Step 2: Create and switch to a feature branch (if not already on one)\n\n```bash\ngit checkout -b fix/payment-api-large-file-upload-500-error\n```\n\n### Step 3: Stage and commit the fix\n\n```bash\ngit add api/payment.py\ngit commit -m \"fix: resolve 500 error in payment API for large file uploads over 10MB\n\nAdded proper chunked upload handling in api/payment.py to support\nfile uploads larger than 10MB. Previously, the payment API would\nreturn a 500 Internal Server Error when attempting to process files\nover this size limit due to missing chunked upload support.\"\n```\n\n### Step 4: Push the branch to remote\n\n```bash\ngit push -u origin fix/payment-api-large-file-upload-500-error\n```\n\n### Step 5: Create the PR using GitHub CLI\n\n```bash\ngh pr create \\\n  --title \"fix: resolve 500 error in payment API for large file uploads over 10MB\" \\\n  --body \"$(cat <<'EOF'\n## Summary\n\nFixes a bug where the payment API was returning a 500 Internal Server Error when processing file uploads larger than 10MB. The root cause was missing chunked upload handling in the payment endpoint.\n\n## Changes\n\n- `api/payment.py`: Added proper chunked upload handling to support files over 10MB\n\n## Problem\n\nWhen a file upload exceeding 10MB was submitted to the payment API, the server would return a 500 error. This was caused by the API attempting to read the entire file into memory at once rather than processing it in chunks.\n\n## Solution\n\nImplemented chunked upload handling in `api/payment.py` so that large files are read and processed in manageable chunks rather than loaded entirely into memory. This prevents memory exhaustion and timeout issues that caused the 500 error.\n\n## Testing\n\n- [ ] Tested with files under 10MB (existing behavior preserved)\n- [ ] Tested with files exactly at 10MB boundary\n- [ ] Tested with files over 10MB (previously failing, now working)\n- [ ] Verified no regression in payment processing for normal uploads\n- [ ] Checked error handling for invalid/corrupt file uploads\n\n## Related Issues\n\nCloses #<issue-number> (if applicable)\nEOF\n)\" \\\n  --base main\n```\n"}], "grading": {"expectations": [{"text": "The PR title starts with 'fix' type since this is a bug fix", "passed": true, "evidence": "response.md line 6: '```fix: resolve 500 error in payment API for large file uploads over 10MB```'. The title clearly begins with 'fix:' indicating the fix type prefix."}, {"text": "The PR title follows the pattern type(scope): Summary", "passed": false, "evidence": "The PR title is 'fix: resolve 500 error in payment API for large file uploads over 10MB'. This follows 'type: Summary' but NOT 'type(scope): Summary'. There is no scope in parentheses (e.g., 'fix(payment):' would satisfy this). The title omits the required (scope) component entirely."}, {"text": "The PR title summary starts with a capital letter", "passed": false, "evidence": "The PR title is 'fix: resolve 500 error in payment API for large file uploads over 10MB'. After the 'fix: ' prefix, the summary begins with lowercase 'r' in 'resolve', not a capital letter."}, {"text": "The response includes a 'gh pr create' command with --title flag", "passed": true, "evidence": "response.md lines 77-110 show: 'gh pr create \\ --title \"fix: resolve 500 error in payment API for large file uploads over 10MB\" ...'. The command is present and includes the --title flag."}, {"text": "The PR body includes a Summary section describing the fix", "passed": true, "evidence": "response.md lines 12-14 show a '## Summary' section in the PR body: 'Fixes a bug where the payment API was returning a 500 Internal Server Error when processing file uploads larger than 10MB. The root cause was missing chunked upload handling in the payment endpoint.' This clearly describes the fix."}, {"text": "The PR body includes a Checklist with PR title format check", "passed": false, "evidence": "The PR body contains a '## Testing' section with a checklist (response.md lines 29-34), but the checklist items are about testing the code functionality (file upload sizes), not about verifying the PR title format. No checklist item checks PR title format compliance. Example items: '- [ ] Tested with files under 10MB', '- [ ] Tested with files over 10MB'."}], "summary": {"passed": 3, "failed": 3, "total": 6, "pass_rate": 0.5}, "execution_metrics": {"total_steps": 5, "errors_encountered": 0, "steps": ["Understood task context and identified bug details", "Composed PR title using conventional commits format", "Composed PR body with Summary, Changes, Problem, Solution, Testing, and Related Issues sections", "Defined full sequence of git and gh commands to create the PR", "Saved all output files (response.md, transcript.md, metrics.json)"], "output_chars": 2891, "transcript_chars": 1851}, "timing": {}, "claims": [{"claim": "The PR title uses conventional commits format", "type": "quality", "verified": true, "evidence": "The title 'fix: resolve 500 error in payment API for large file uploads over 10MB' uses the conventional commits 'type: description' format, though it omits the optional (scope) component."}, {"claim": "The PR body follows standard conventions with Summary, Changes, Problem, Solution, Testing, Related Issues sections", "type": "factual", "verified": true, "evidence": "response.md confirms all six sections are present: ## Summary, ## Changes, ## Problem, ## Solution, ## Testing, ## Related Issues."}, {"claim": "No skill was used for this task (baseline evaluation run)", "type": "process", "verified": true, "evidence": "transcript.md line 47: 'No skill was used for this task (baseline evaluation run)'. The outputs directory is under 'without_skill' path."}, {"claim": "Branch naming follows kebab-case convention with fix/ prefix", "type": "factual", "verified": true, "evidence": "response.md line 53: 'git checkout -b fix/payment-api-large-file-upload-500-error' confirms kebab-case with fix/ prefix."}], "user_notes_summary": {}, "eval_feedback": {"suggestions": [{"assertion": "The PR title follows the pattern type(scope): Summary", "reason": "This assertion is discriminating and correctly identified a real gap: the executor did not include a scope. However, the assertion assumes scope is mandatory in conventional commits, where it is actually optional. If scope is optional for this PR workflow, this assertion would need clarification. If it is required, the assertion is well-placed and caught a genuine omission."}, {"assertion": "The PR title summary starts with a capital letter", "reason": "This is a meaningful style check and correctly caught that 'resolve' starts with lowercase. Worth keeping as-is since it tests a specific formatting convention."}, {"assertion": "The PR body includes a Checklist with PR title format check", "reason": "This assertion tests a very specific requirement (a checklist item verifying PR title format), which is an unusual convention. The executor provided a standard testing checklist for the code changes instead. The assertion would benefit from clarification: is a PR-title-format checklist a standard requirement of the skill being evaluated, or is this a misspecified expectation? If this is a real skill requirement, it should be documented clearly in the skill prompt."}, {"reason": "No assertion checks whether the gh pr create command includes a --base flag or --body flag with proper content. The command in response.md does use --body and --base main, which are important for correctness, but neither is asserted."}, {"reason": "No assertion checks whether the PR body was actually included in the gh pr create command (not just defined separately). The executor did include the body inline in the gh command, but this could have been omitted. An assertion like 'The gh pr create command includes the --body flag with the PR body content' would catch cases where the command is incomplete."}], "overall": "Three of the six assertions are well-targeted and caught real issues (missing scope, lowercase summary start, wrong checklist content). The checklist assertion for PR title format is unusual and may reflect a skill-specific requirement that was not clearly communicated in the task prompt, making it hard for the executor to satisfy without explicit instructions."}}}], "previous_feedback": {}, "previous_outputs": {}, "benchmark": {"metadata": {"skill_name": "create-pr", "skill_path": "plugins/create-pr/skills/create-pr", "executor_model": "<model-name>", "analyzer_model": "<model-name>", "timestamp": "2026-02-28T08:26:19Z", "evals_run": [1, 2, 3], "runs_per_configuration": 3}, "runs": [{"eval_id": 3, "configuration": "with_skill", "run_number": 1, "result": {"pass_rate": 0.8, "passed": 4, "failed": 1, "total": 5, "time_seconds": 0.0, "tokens": 0, "tool_calls": 0, "errors": 0}, "expectations": [{"text": "The PR title uses 'docs' type since the changes are documentation only", "passed": true, "evidence": "PR title in response.md is 'docs: Update README installation instructions and add API reference'. Transcript Step 3 states: 'Type determination: Both changed files are documentation (README.md, docs/api-reference.md) -> type is docs'. response.md Step 2 confirms: 'Type: docs \u2014 Both changes are documentation-only updates'."}, {"text": "The PR title follows the conventional commit format", "passed": true, "evidence": "The title 'docs: Update README installation instructions and add API reference' is explicitly validated in both transcript (Step 4) and response.md against the pattern '^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$'. All four criteria are confirmed: valid type 'docs', scope correctly omitted, summary starts with capital 'U', summary does not end with a period."}, {"text": "The response checks git status or git diff as part of the workflow", "passed": false, "evidence": "The transcript (Step 2) says 'Would run: git status, git diff --stat, git log origin/main..HEAD --oneline' and labels the described output as 'These commands reveal:' \u2014 but this is purely hypothetical. response.md Step 1 similarly says 'Commands I would run' and 'Expected output (hypothetical)'. No actual git commands were executed; the entire state-checking step was simulated without real tool calls."}, {"text": "The PR body includes a Summary section", "passed": true, "evidence": "response.md contains '## Summary' as the first PR body section with substantive content: a two-item numbered list describing the README.md and docs/api-reference.md changes, plus a verification note. Transcript Step 6 also confirms the body includes a 'Summary section describing both documentation changes'."}, {"text": "The PR body contains a Checklist section", "passed": true, "evidence": "response.md contains '## Checklist' section with three items: '[x] PR title follows conventional commit format', '[ ] Tests included', and '[x] Documentation updated (if applicable)'. The full gh command in response.md also embeds this checklist in the --body argument."}], "notes": []}, {"eval_id": 1, "configuration": "with_skill", "run_number": 1, "result": {"pass_rate": 1.0, "passed": 9, "failed": 0, "total": 9, "time_seconds": 0.0, "tokens": 3726, "tool_calls": null, "errors": 0}, "expectations": [{"text": "The PR title follows the conventional commit format: type(scope): Summary", "passed": true, "evidence": "response.md line 56: 'feat(auth): Add OAuth2 login support with JWT authentication' \u2014 matches the pattern type(scope): Summary exactly. The transcript also validates against the regex: ^(feat|fix|perf|test|docs|refactor|build|ci|chore|revert)(\\([a-zA-Z0-9 -]+\\))?!?: [A-Z].+[^.]$"}, {"text": "The PR title uses one of the valid types: feat, fix, perf, test, docs, refactor, build, ci, chore, or revert", "passed": true, "evidence": "response.md line 56: PR title uses type 'feat', which is explicitly listed as a valid type. The response also calls this out: 'Type: feat - valid'"}, {"text": "The PR title summary starts with a capital letter", "passed": true, "evidence": "response.md line 56: The summary portion is 'Add OAuth2 login support with JWT authentication' \u2014 begins with capital 'A'. The response confirms: 'Summary starts with capital \"A\" - valid'"}, {"text": "The PR title summary does not end with a period", "passed": true, "evidence": "response.md line 56: The title ends with '...JWT authentication' \u2014 no trailing period. The response confirms: 'Summary does not end with period - valid'"}, {"text": "The response includes a 'gh pr create' command", "passed": true, "evidence": "response.md line 69: Full command beginning with 'gh pr create --title \"feat(auth): Add OAuth2 login support with JWT authentication\" --body \"$(cat <<'EOF'' is present, including the complete PR body as a heredoc."}, {"text": "The PR body contains a Summary section", "passed": true, "evidence": "response.md lines 71 and 113: '## Summary' section appears both in the gh CLI command heredoc body and in the rendered PR body section, with substantive content describing the OAuth2 and JWT changes."}, {"text": "The PR body contains a Related Issues section", "passed": true, "evidence": "response.md lines 95 and 137: '## Related Issues' section appears in both the heredoc and rendered PR body, containing a comment placeholder '<!-- Use \"closes #<issue-number>\", \"fixes #<issue-number>\", or \"resolves #<issue-number>\" to auto-close issues -->'."}, {"text": "The PR body contains a Checklist section", "passed": true, "evidence": "response.md lines 99 and 141: '## Checklist' section appears in both the heredoc and rendered PR body with three checklist items: PR title format (checked), Tests included (checked), Documentation updated (unchecked)."}, {"text": "The response includes or mentions a git push command", "passed": true, "evidence": "response.md line 48: 'git push -u origin HEAD' appears as a bash command block under '## Step 3: Push Branch'. The transcript (Step 4) also documents this command with explanation that it 'pushes the current branch to the remote and sets the upstream tracking reference'."}], "notes": []}, {"eval_id": 2, "configuration": "with_skill", "run_number": 1, "result": {"pass_rate": 1.0, "passed": 6, "failed": 0, "total": 6, "time_seconds": 0.0, "tokens": 0, "tool_calls": 0, "errors": 0}, "expectations": [{"text": "The PR title starts with 'fix' type since this is a bug fix", "passed": true, "evidence": "The PR title in response.md is 'fix(api): Handle chunked uploads in payment API to fix 500 on large files', which starts with the 'fix' type."}, {"text": "The PR title follows the pattern type(scope): Summary", "passed": true, "evidence": "The title 'fix(api): Handle chunked uploads in payment API to fix 500 on large files' follows the exact pattern type(scope): Summary \u2014 type='fix', scope='api' in parentheses, colon+space, then the summary."}, {"text": "The PR title summary starts with a capital letter", "passed": true, "evidence": "The summary portion of the title is 'Handle chunked uploads in payment API to fix 500 on large files', which begins with 'H' (capital letter). This is also validated in the transcript Step 4: 'Summary starts with \"H\" (capital letter): valid'."}, {"text": "The response includes a 'gh pr create' command with --title flag", "passed": true, "evidence": "response.md line 81 shows: 'gh pr create --title \"fix(api): Handle chunked uploads in payment API to fix 500 on large files\" --body \"$(cat <<\\'EOF\\''. The full gh CLI command with --title flag is present under the '### Full gh CLI Command' section."}, {"text": "The PR body includes a Summary section describing the fix", "passed": true, "evidence": "response.md contains '## Summary' section with a substantive description: 'Fixes a 500 Internal Server Error that occurred when uploading files larger than 10MB through the payment API (`api/payment.py`).' It also includes Root Cause, Fix, and How to test subsections, providing a thorough description of the bug and its resolution."}, {"text": "The PR body includes a Checklist with PR title format check", "passed": true, "evidence": "response.md contains '## Checklist' section with '- [x] PR title follows conventional commit format' checked, along with '- [ ] Tests included' and '- [ ] Documentation updated (if applicable)' unchecked."}], "notes": []}, {"eval_id": 3, "configuration": "without_skill", "run_number": 1, "result": {"pass_rate": 0.8, "passed": 4, "failed": 1, "total": 5, "time_seconds": 0.0, "tokens": 0, "tool_calls": 0, "errors": 0}, "expectations": [{"text": "The PR title uses 'docs' type since the changes are documentation only", "passed": true, "evidence": "The PR title in response.md is: 'docs: improve installation instructions and add API reference documentation'. It explicitly uses the 'docs' type prefix."}, {"text": "The PR title follows the conventional commit format", "passed": true, "evidence": "The PR title 'docs: improve installation instructions and add API reference documentation' follows the conventional commit format of '<type>: <description>'. The type is 'docs' and the description is a plain-English summary of the changes."}, {"text": "The response checks git status or git diff as part of the workflow", "passed": false, "evidence": "The agent did not actually execute git status or git diff. The transcript states explicitly: 'Since this is a hypothetical repository, the actual commands cannot be executed, so the exact commands to run are shown instead.' While git status appears as step 1 in the proposed command sequence in response.md, it was listed as a command to run rather than actually executed. No tool calls to Bash were made to check git status or diff."}, {"text": "The PR body includes a Summary section", "passed": true, "evidence": "The PR body in response.md contains '## Summary' with two bullet points: 'Updated README.md with clearer and more comprehensive installation instructions' and 'Added docs/api-reference.md with full API documentation'."}, {"text": "The PR body contains a Checklist section", "passed": true, "evidence": "The PR body in response.md contains a '## Test plan' section with four checkbox items using '- [ ]' markdown checklist syntax. While the section heading is 'Test plan' rather than 'Checklist', the content is a genuine markdown checklist covering link verification, installation step validation, API doc review, and code example checking."}], "notes": []}, {"eval_id": 1, "configuration": "without_skill", "run_number": 1, "result": {"pass_rate": 0.78, "passed": 7, "failed": 2, "total": 9, "time_seconds": 0.0, "tokens": 0, "tool_calls": 0, "errors": 0}, "expectations": [{"text": "The PR title follows the conventional commit format: type(scope): Summary", "passed": true, "evidence": "PR title in response.md is: `feat(auth): add OAuth2 login support with JWT authentication`. This matches the pattern type(scope): summary exactly \u2014 'feat' is the type, 'auth' is the scope, and the remainder is the summary."}, {"text": "The PR title uses one of the valid types: feat, fix, perf, test, docs, refactor, build, ci, chore, or revert", "passed": true, "evidence": "The PR title begins with 'feat', which is explicitly listed as a valid type. Confirmed in response.md line 5: `feat(auth): add OAuth2 login support with JWT authentication`."}, {"text": "The PR title summary starts with a capital letter", "passed": false, "evidence": "The summary portion of the PR title (after 'feat(auth): ') is 'add OAuth2 login support with JWT authentication'. It begins with a lowercase 'a', not a capital letter. Found in response.md line 5 and also in the gh pr create command at line 83."}, {"text": "The PR title summary does not end with a period", "passed": true, "evidence": "The PR title ends with 'authentication' \u2014 no trailing period. Confirmed in response.md line 5: `feat(auth): add OAuth2 login support with JWT authentication`."}, {"text": "The response includes a 'gh pr create' command", "passed": true, "evidence": "response.md contains a full gh pr create command starting at line 82: `gh pr create \\` with --title, --body, --base, and --head flags fully specified."}, {"text": "The PR body contains a Summary section", "passed": true, "evidence": "The PR body in response.md (lines 13-17 and mirrored in the gh pr create heredoc at lines 85-90) contains a `## Summary` section with three bullet points describing what the PR does."}, {"text": "The PR body contains a Related Issues section", "passed": true, "evidence": "The PR body in response.md (line 49-51 and mirrored in the gh pr create heredoc at lines 120-123) contains a `## Related Issues` section with the placeholder text 'Closes #<issue-number>'."}, {"text": "The PR body contains a Checklist section", "passed": false, "evidence": "The PR body does not contain a section named 'Checklist'. The closest section is '## Test Plan' (lines 28-34 in the body) which uses checkbox syntax (`- [x]`), but it is not labeled 'Checklist'. No section with that name appears anywhere in response.md."}, {"text": "The response includes or mentions a git push command", "passed": true, "evidence": "response.md line 79 contains: `git push -u origin feat/jwt-oauth2-auth` as step 6 in the commands sequence, preceded by the comment '# 6. Push the feature branch to remote'."}], "notes": []}, {"eval_id": 2, "configuration": "without_skill", "run_number": 1, "result": {"pass_rate": 0.5, "passed": 3, "failed": 3, "total": 6, "time_seconds": 0.0, "tokens": 2891, "tool_calls": 0, "errors": 0}, "expectations": [{"text": "The PR title starts with 'fix' type since this is a bug fix", "passed": true, "evidence": "response.md line 6: '```fix: resolve 500 error in payment API for large file uploads over 10MB```'. The title clearly begins with 'fix:' indicating the fix type prefix."}, {"text": "The PR title follows the pattern type(scope): Summary", "passed": false, "evidence": "The PR title is 'fix: resolve 500 error in payment API for large file uploads over 10MB'. This follows 'type: Summary' but NOT 'type(scope): Summary'. There is no scope in parentheses (e.g., 'fix(payment):' would satisfy this). The title omits the required (scope) component entirely."}, {"text": "The PR title summary starts with a capital letter", "passed": false, "evidence": "The PR title is 'fix: resolve 500 error in payment API for large file uploads over 10MB'. After the 'fix: ' prefix, the summary begins with lowercase 'r' in 'resolve', not a capital letter."}, {"text": "The response includes a 'gh pr create' command with --title flag", "passed": true, "evidence": "response.md lines 77-110 show: 'gh pr create \\ --title \"fix: resolve 500 error in payment API for large file uploads over 10MB\" ...'. The command is present and includes the --title flag."}, {"text": "The PR body includes a Summary section describing the fix", "passed": true, "evidence": "response.md lines 12-14 show a '## Summary' section in the PR body: 'Fixes a bug where the payment API was returning a 500 Internal Server Error when processing file uploads larger than 10MB. The root cause was missing chunked upload handling in the payment endpoint.' This clearly describes the fix."}, {"text": "The PR body includes a Checklist with PR title format check", "passed": false, "evidence": "The PR body contains a '## Testing' section with a checklist (response.md lines 29-34), but the checklist items are about testing the code functionality (file upload sizes), not about verifying the PR title format. No checklist item checks PR title format compliance. Example items: '- [ ] Tested with files under 10MB', '- [ ] Tested with files over 10MB'."}], "notes": []}], "run_summary": {"with_skill": {"pass_rate": {"mean": 0.9333, "stddev": 0.1155, "min": 0.8, "max": 1.0}, "time_seconds": {"mean": 0.0, "stddev": 0.0, "min": 0.0, "max": 0.0}, "tokens": {"mean": 1242.0, "stddev": 2151.2071, "min": 0, "max": 3726}}, "without_skill": {"pass_rate": {"mean": 0.6933, "stddev": 0.1677, "min": 0.5, "max": 0.8}, "time_seconds": {"mean": 0.0, "stddev": 0.0, "min": 0.0, "max": 0.0}, "tokens": {"mean": 963.6667, "stddev": 1669.1196, "min": 0, "max": 2891}}, "delta": {"pass_rate": "+0.24", "time_seconds": "+0.0", "tokens": "+278"}}, "notes": []}};

    // ---- State ----
    let feedbackMap = {};  // run_id -> feedback text
    let currentIndex = 0;
    let visitedRuns = new Set();

    // ---- Init ----
    async function init() {
      // Load saved feedback from server  but only if this isn't a fresh
      // iteration (indicated by previous_feedback being present). When
      // previous feedback exists, the feedback.json on disk is stale from
      // the prior iteration and should not pre-fill the textareas.
      const hasPrevious = Object.keys(EMBEDDED_DATA.previous_feedback || {}).length > 0
        || Object.keys(EMBEDDED_DATA.previous_outputs || {}).length > 0;
      if (!hasPrevious) {
        try {
          const resp = await fetch("/api/feedback");
          const data = await resp.json();
          if (data.reviews) {
            for (const r of data.reviews) feedbackMap[r.run_id] = r.feedback;
          }
        } catch { /* first run, no feedback yet */ }
      }

      document.getElementById("skill-name").textContent = EMBEDDED_DATA.skill_name;
      showRun(0);

      // Wire up feedback auto-save
      const textarea = document.getElementById("feedback");
      let saveTimeout = null;
      textarea.addEventListener("input", () => {
        clearTimeout(saveTimeout);
        document.getElementById("feedback-status").textContent = "";
        saveTimeout = setTimeout(() => saveCurrentFeedback(), 800);
      });
    }

    // ---- Navigation ----
    function navigate(delta) {
      const newIndex = currentIndex + delta;
      if (newIndex >= 0 && newIndex < EMBEDDED_DATA.runs.length) {
        saveCurrentFeedback();
        showRun(newIndex);
      }
    }

    function updateNavButtons() {
      document.getElementById("prev-btn").disabled = currentIndex === 0;
      document.getElementById("next-btn").disabled =
        currentIndex === EMBEDDED_DATA.runs.length - 1;
    }

    // ---- Show a run ----
    function showRun(index) {
      currentIndex = index;
      const run = EMBEDDED_DATA.runs[index];

      // Progress
      document.getElementById("progress").textContent =
        `${index + 1} of ${EMBEDDED_DATA.runs.length}`;

      // Prompt
      document.getElementById("prompt-text").textContent = run.prompt;

      // Config badge
      const badge = document.getElementById("config-badge");
      const configMatch = run.id.match(/(with_skill|without_skill|new_skill|old_skill)/);
      if (configMatch) {
        const config = configMatch[1];
        const isBaseline = config === "without_skill" || config === "old_skill";
        badge.textContent = config.replace(/_/g, " ");
        badge.className = "config-badge " + (isBaseline ? "config-baseline" : "config-primary");
        badge.style.display = "inline-block";
      } else {
        badge.style.display = "none";
      }

      // Outputs
      renderOutputs(run);

      // Previous outputs
      renderPrevOutputs(run);

      // Grades
      renderGrades(run);

      // Previous feedback
      const prevFb = (EMBEDDED_DATA.previous_feedback || {})[run.id];
      const prevEl = document.getElementById("prev-feedback");
      if (prevFb) {
        document.getElementById("prev-feedback-text").textContent = prevFb;
        prevEl.style.display = "block";
      } else {
        prevEl.style.display = "none";
      }

      // Feedback
      document.getElementById("feedback").value = feedbackMap[run.id] || "";
      document.getElementById("feedback-status").textContent = "";

      updateNavButtons();

      // Track visited runs and promote done button when all visited
      visitedRuns.add(index);
      const doneBtn = document.getElementById("done-btn");
      if (visitedRuns.size >= EMBEDDED_DATA.runs.length) {
        doneBtn.classList.add("ready");
      }

      // Scroll main content to top
      document.querySelector(".main").scrollTop = 0;
    }

    // ---- Render outputs ----
    function renderOutputs(run) {
      const container = document.getElementById("outputs-body");
      container.innerHTML = "";

      const outputs = run.outputs || [];
      if (outputs.length === 0) {
        container.innerHTML = '<div class="empty-state">No output files</div>';
        return;
      }

      for (const file of outputs) {
        const fileDiv = document.createElement("div");
        fileDiv.className = "output-file";

        // Always show file header with download link
        const header = document.createElement("div");
        header.className = "output-file-header";
        const nameSpan = document.createElement("span");
        nameSpan.textContent = file.name;
        header.appendChild(nameSpan);
        const dlBtn = document.createElement("a");
        dlBtn.className = "dl-btn";
        dlBtn.textContent = "Download";
        dlBtn.download = file.name;
        dlBtn.href = getDownloadUri(file);
        header.appendChild(dlBtn);
        fileDiv.appendChild(header);

        const content = document.createElement("div");
        content.className = "output-file-content";

        if (file.type === "text") {
          const pre = document.createElement("pre");
          pre.textContent = file.content;
          content.appendChild(pre);
        } else if (file.type === "image") {
          const img = document.createElement("img");
          img.src = file.data_uri;
          img.alt = file.name;
          content.appendChild(img);
        } else if (file.type === "pdf") {
          const iframe = document.createElement("iframe");
          iframe.src = file.data_uri;
          content.appendChild(iframe);
        } else if (file.type === "xlsx") {
          renderXlsx(content, file.data_b64);
        } else if (file.type === "binary") {
          const a = document.createElement("a");
          a.className = "download-link";
          a.href = file.data_uri;
          a.download = file.name;
          a.textContent = "Download " + file.name;
          content.appendChild(a);
        } else if (file.type === "error") {
          const pre = document.createElement("pre");
          pre.textContent = file.content;
          pre.style.color = "var(--red)";
          content.appendChild(pre);
        }

        fileDiv.appendChild(content);
        container.appendChild(fileDiv);
      }
    }

    // ---- XLSX rendering via SheetJS ----
    function renderXlsx(container, b64Data) {
      try {
        const raw = Uint8Array.from(atob(b64Data), c => c.charCodeAt(0));
        const wb = XLSX.read(raw, { type: "array" });

        for (let i = 0; i < wb.SheetNames.length; i++) {
          const sheetName = wb.SheetNames[i];
          const ws = wb.Sheets[sheetName];

          if (wb.SheetNames.length > 1) {
            const sheetLabel = document.createElement("div");
            sheetLabel.style.cssText =
              "font-weight:600; font-size:0.8rem; color:#b0aea5; margin-top:0.5rem; margin-bottom:0.25rem;";
            sheetLabel.textContent = "Sheet: " + sheetName;
            container.appendChild(sheetLabel);
          }

          const htmlStr = XLSX.utils.sheet_to_html(ws, { editable: false });
          const wrapper = document.createElement("div");
          wrapper.innerHTML = htmlStr;
          container.appendChild(wrapper);
        }
      } catch (err) {
        container.textContent = "Error rendering spreadsheet: " + err.message;
      }
    }

    // ---- Grades ----
    function renderGrades(run) {
      const section = document.getElementById("grades-section");
      const content = document.getElementById("grades-content");

      if (!run.grading) {
        section.style.display = "none";
        return;
      }

      const grading = run.grading;
      section.style.display = "block";
      // Reset to collapsed
      content.classList.remove("open");
      document.getElementById("grades-arrow").classList.remove("open");

      const summary = grading.summary || {};
      const expectations = grading.expectations || [];

      let html = '<div style="padding: 1rem;">';

      // Summary line
      const passRate = summary.pass_rate != null
        ? Math.round(summary.pass_rate * 100) + "%"
        : "?";
      const badgeClass = summary.pass_rate >= 0.8 ? "grade-pass" : summary.pass_rate >= 0.5 ? "" : "grade-fail";
      html += '<div class="grades-summary">';
      html += '<span class="grade-badge ' + badgeClass + '">' + passRate + '</span>';
      html += '<span>' + (summary.passed || 0) + ' passed, ' + (summary.failed || 0) + ' failed of ' + (summary.total || 0) + '</span>';
      html += '</div>';

      // Assertions list
      html += '<ul class="assertion-list">';
      for (const exp of expectations) {
        const statusClass = exp.passed ? "pass" : "fail";
        const statusIcon = exp.passed ? "\u2713" : "\u2717";
        html += '<li class="assertion-item">';
        html += '<span class="assertion-status ' + statusClass + '">' + statusIcon + '</span>';
        html += '<span>' + escapeHtml(exp.text) + '</span>';
        if (exp.evidence) {
          html += '<div class="assertion-evidence">' + escapeHtml(exp.evidence) + '</div>';
        }
        html += '</li>';
      }
      html += '</ul>';

      html += '</div>';
      content.innerHTML = html;
    }

    function toggleGrades() {
      const content = document.getElementById("grades-content");
      const arrow = document.getElementById("grades-arrow");
      content.classList.toggle("open");
      arrow.classList.toggle("open");
    }

    // ---- Previous outputs (collapsible) ----
    function renderPrevOutputs(run) {
      const section = document.getElementById("prev-outputs-section");
      const content = document.getElementById("prev-outputs-content");
      const prevOutputs = (EMBEDDED_DATA.previous_outputs || {})[run.id];

      if (!prevOutputs || prevOutputs.length === 0) {
        section.style.display = "none";
        return;
      }

      section.style.display = "block";
      // Reset to collapsed
      content.classList.remove("open");
      document.getElementById("prev-outputs-arrow").classList.remove("open");

      // Render the files into the content area
      content.innerHTML = "";
      const wrapper = document.createElement("div");
      wrapper.style.padding = "1rem";

      for (const file of prevOutputs) {
        const fileDiv = document.createElement("div");
        fileDiv.className = "output-file";

        const header = document.createElement("div");
        header.className = "output-file-header";
        const nameSpan = document.createElement("span");
        nameSpan.textContent = file.name;
        header.appendChild(nameSpan);
        const dlBtn = document.createElement("a");
        dlBtn.className = "dl-btn";
        dlBtn.textContent = "Download";
        dlBtn.download = file.name;
        dlBtn.href = getDownloadUri(file);
        header.appendChild(dlBtn);
        fileDiv.appendChild(header);

        const fc = document.createElement("div");
        fc.className = "output-file-content";

        if (file.type === "text") {
          const pre = document.createElement("pre");
          pre.textContent = file.content;
          fc.appendChild(pre);
        } else if (file.type === "image") {
          const img = document.createElement("img");
          img.src = file.data_uri;
          img.alt = file.name;
          fc.appendChild(img);
        } else if (file.type === "pdf") {
          const iframe = document.createElement("iframe");
          iframe.src = file.data_uri;
          fc.appendChild(iframe);
        } else if (file.type === "xlsx") {
          renderXlsx(fc, file.data_b64);
        } else if (file.type === "binary") {
          const a = document.createElement("a");
          a.className = "download-link";
          a.href = file.data_uri;
          a.download = file.name;
          a.textContent = "Download " + file.name;
          fc.appendChild(a);
        }

        fileDiv.appendChild(fc);
        wrapper.appendChild(fileDiv);
      }

      content.appendChild(wrapper);
    }

    function togglePrevOutputs() {
      const content = document.getElementById("prev-outputs-content");
      const arrow = document.getElementById("prev-outputs-arrow");
      content.classList.toggle("open");
      arrow.classList.toggle("open");
    }

    // ---- Feedback (saved to server -> feedback.json) ----
    function saveCurrentFeedback() {
      const run = EMBEDDED_DATA.runs[currentIndex];
      const text = document.getElementById("feedback").value;

      if (text.trim() === "") {
        delete feedbackMap[run.id];
      } else {
        feedbackMap[run.id] = text;
      }

      // Build reviews array from map
      const reviews = [];
      for (const [run_id, feedback] of Object.entries(feedbackMap)) {
        if (feedback.trim()) {
          reviews.push({ run_id, feedback, timestamp: new Date().toISOString() });
        }
      }

      fetch("/api/feedback", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ reviews, status: "in_progress" }),
      }).then(() => {
        document.getElementById("feedback-status").textContent = "Saved";
      }).catch(() => {
        // Static mode or server unavailable  no-op on auto-save,
        // feedback will be downloaded on final submit
        document.getElementById("feedback-status").textContent = "Will download on submit";
      });
    }

    // ---- Done ----
    function showDoneDialog() {
      // Save current textarea to feedbackMap (but don't POST yet)
      const run = EMBEDDED_DATA.runs[currentIndex];
      const text = document.getElementById("feedback").value;
      if (text.trim() === "") {
        delete feedbackMap[run.id];
      } else {
        feedbackMap[run.id] = text;
      }

      // POST once with status: complete  include ALL runs so the model
      // can distinguish "no feedback" (looks good) from "not reviewed"
      const reviews = [];
      const ts = new Date().toISOString();
      for (const r of EMBEDDED_DATA.runs) {
        reviews.push({ run_id: r.id, feedback: feedbackMap[r.id] || "", timestamp: ts });
      }
      const payload = JSON.stringify({ reviews, status: "complete" }, null, 2);
      fetch("/api/feedback", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: payload,
      }).then(() => {
        document.getElementById("done-overlay").classList.add("visible");
      }).catch(() => {
        // Server not available (static mode)  download as file
        const blob = new Blob([payload], { type: "application/json" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = "feedback.json";
        a.click();
        URL.revokeObjectURL(url);
        document.getElementById("done-overlay").classList.add("visible");
      });
    }

    function closeDoneDialog() {
      // Reset status back to in_progress
      saveCurrentFeedback();
      document.getElementById("done-overlay").classList.remove("visible");
    }

    // ---- Toast ----
    function showToast(message) {
      const toast = document.getElementById("toast");
      toast.textContent = message;
      toast.classList.add("visible");
      setTimeout(() => toast.classList.remove("visible"), 2000);
    }

    // ---- Keyboard nav ----
    document.addEventListener("keydown", (e) => {
      // Don't capture when typing in textarea
      if (e.target.tagName === "TEXTAREA") return;

      if (e.key === "ArrowLeft" || e.key === "ArrowUp") {
        e.preventDefault();
        navigate(-1);
      } else if (e.key === "ArrowRight" || e.key === "ArrowDown") {
        e.preventDefault();
        navigate(1);
      }
    });

    // ---- Util ----
    function getDownloadUri(file) {
      if (file.data_uri) return file.data_uri;
      if (file.data_b64) return "data:application/octet-stream;base64," + file.data_b64;
      if (file.type === "text") return "data:text/plain;charset=utf-8," + encodeURIComponent(file.content);
      return "#";
    }

    function escapeHtml(text) {
      const div = document.createElement("div");
      div.textContent = text;
      return div.innerHTML;
    }

    // ---- View switching ----
    function switchView(view) {
      document.querySelectorAll(".view-tab").forEach(t => t.classList.remove("active"));
      document.querySelectorAll(".view-panel").forEach(p => p.classList.remove("active"));
      document.querySelector(`[onclick="switchView('${view}')"]`).classList.add("active");
      document.getElementById("panel-" + view).classList.add("active");
    }

    // ---- Benchmark rendering ----
    function renderBenchmark() {
      const data = EMBEDDED_DATA.benchmark;
      if (!data) return;

      // Show the tabs
      document.getElementById("view-tabs").style.display = "flex";

      const container = document.getElementById("benchmark-content");
      const summary = data.run_summary || {};
      const metadata = data.metadata || {};
      const notes = data.notes || [];

      let html = "";

      // Header
      html += "<h2 style='font-family: Poppins, sans-serif; margin-bottom: 0.5rem;'>Benchmark Results</h2>";
      html += "<p style='color: var(--text-muted); font-size: 0.875rem; margin-bottom: 1.25rem;'>";
      if (metadata.skill_name) html += "<strong>" + escapeHtml(metadata.skill_name) + "</strong> &mdash; ";
      if (metadata.timestamp) html += metadata.timestamp + " &mdash; ";
      if (metadata.evals_run) html += "Evals: " + metadata.evals_run.join(", ") + " &mdash; ";
      html += (metadata.runs_per_configuration || "?") + " runs per configuration";
      html += "</p>";

      // Summary table
      html += '<table class="benchmark-table">';

      function fmtStat(stat, pct) {
        if (!stat) return "";
        const suffix = pct ? "%" : "";
        const m = pct ? (stat.mean * 100).toFixed(0) : stat.mean.toFixed(1);
        const s = pct ? (stat.stddev * 100).toFixed(0) : stat.stddev.toFixed(1);
        return m + suffix + "  " + s + suffix;
      }

      function deltaClass(val) {
        if (!val) return "";
        const n = parseFloat(val);
        if (n > 0) return "benchmark-delta-positive";
        if (n < 0) return "benchmark-delta-negative";
        return "";
      }

      // Discover config names dynamically (everything except "delta")
      const configs = Object.keys(summary).filter(k => k !== "delta");
      const configA = configs[0] || "config_a";
      const configB = configs[1] || "config_b";
      const labelA = configA.replace(/_/g, " ").replace(/\b\w/g, c => c.toUpperCase());
      const labelB = configB.replace(/_/g, " ").replace(/\b\w/g, c => c.toUpperCase());
      const a = summary[configA] || {};
      const b = summary[configB] || {};
      const delta = summary.delta || {};

      html += "<thead><tr><th>Metric</th><th>" + escapeHtml(labelA) + "</th><th>" + escapeHtml(labelB) + "</th><th>Delta</th></tr></thead>";
      html += "<tbody>";

      html += "<tr><td><strong>Pass Rate</strong></td>";
      html += "<td>" + fmtStat(a.pass_rate, true) + "</td>";
      html += "<td>" + fmtStat(b.pass_rate, true) + "</td>";
      html += '<td class="' + deltaClass(delta.pass_rate) + '">' + (delta.pass_rate || "") + "</td></tr>";

      // Time (only show row if data exists)
      if (a.time_seconds || b.time_seconds) {
        html += "<tr><td><strong>Time (s)</strong></td>";
        html += "<td>" + fmtStat(a.time_seconds, false) + "</td>";
        html += "<td>" + fmtStat(b.time_seconds, false) + "</td>";
        html += '<td class="' + deltaClass(delta.time_seconds) + '">' + (delta.time_seconds ? delta.time_seconds + "s" : "") + "</td></tr>";
      }

      // Tokens (only show row if data exists)
      if (a.tokens || b.tokens) {
        html += "<tr><td><strong>Tokens</strong></td>";
        html += "<td>" + fmtStat(a.tokens, false) + "</td>";
        html += "<td>" + fmtStat(b.tokens, false) + "</td>";
        html += '<td class="' + deltaClass(delta.tokens) + '">' + (delta.tokens || "") + "</td></tr>";
      }

      html += "</tbody></table>";

      // Per-eval breakdown (if runs data available)
      const runs = data.runs || [];
      if (runs.length > 0) {
        const evalIds = [...new Set(runs.map(r => r.eval_id))].sort((a, b) => a - b);

        html += "<h3 style='font-family: Poppins, sans-serif; margin-bottom: 0.75rem;'>Per-Eval Breakdown</h3>";

        const hasTime = runs.some(r => r.result && r.result.time_seconds != null);
        const hasErrors = runs.some(r => r.result && r.result.errors > 0);

        for (const evalId of evalIds) {
          const evalRuns = runs.filter(r => r.eval_id === evalId);
          const evalName = evalRuns[0] && evalRuns[0].eval_name ? evalRuns[0].eval_name : "Eval " + evalId;

          html += "<h4 style='font-family: Poppins, sans-serif; margin: 1rem 0 0.5rem; color: var(--text);'>" + escapeHtml(evalName) + "</h4>";
          html += '<table class="benchmark-table">';
          html += "<thead><tr><th>Config</th><th>Run</th><th>Pass Rate</th>";
          if (hasTime) html += "<th>Time (s)</th>";
          if (hasErrors) html += "<th>Crashes During Execution</th>";
          html += "</tr></thead>";
          html += "<tbody>";

          // Group by config and render with average rows
          const configGroups = [...new Set(evalRuns.map(r => r.configuration))];
          for (let ci = 0; ci < configGroups.length; ci++) {
            const config = configGroups[ci];
            const configRuns = evalRuns.filter(r => r.configuration === config);
            if (configRuns.length === 0) continue;

            const rowClass = ci === 0 ? "benchmark-row-with" : "benchmark-row-without";
            const configLabel = config.replace(/_/g, " ").replace(/\b\w/g, c => c.toUpperCase());

            for (const run of configRuns) {
              const r = run.result || {};
              const prClass = r.pass_rate >= 0.8 ? "benchmark-delta-positive" : r.pass_rate < 0.5 ? "benchmark-delta-negative" : "";
              html += '<tr class="' + rowClass + '">';
              html += "<td>" + configLabel + "</td>";
              html += "<td>" + run.run_number + "</td>";
              html += '<td class="' + prClass + '">' + ((r.pass_rate || 0) * 100).toFixed(0) + "% (" + (r.passed || 0) + "/" + (r.total || 0) + ")</td>";
              if (hasTime) html += "<td>" + (r.time_seconds != null ? r.time_seconds.toFixed(1) : "") + "</td>";
              if (hasErrors) html += "<td>" + (r.errors || 0) + "</td>";
              html += "</tr>";
            }

            // Average row
            const rates = configRuns.map(r => (r.result || {}).pass_rate || 0);
            const avgRate = rates.reduce((a, b) => a + b, 0) / rates.length;
            const avgPrClass = avgRate >= 0.8 ? "benchmark-delta-positive" : avgRate < 0.5 ? "benchmark-delta-negative" : "";
            html += '<tr class="benchmark-row-avg ' + rowClass + '">';
            html += "<td>" + configLabel + "</td>";
            html += "<td>Avg</td>";
            html += '<td class="' + avgPrClass + '">' + (avgRate * 100).toFixed(0) + "%</td>";
            if (hasTime) {
              const times = configRuns.map(r => (r.result || {}).time_seconds).filter(t => t != null);
              html += "<td>" + (times.length ? (times.reduce((a, b) => a + b, 0) / times.length).toFixed(1) : "") + "</td>";
            }
            if (hasErrors) html += "<td></td>";
            html += "</tr>";
          }
          html += "</tbody></table>";

          // Per-assertion detail for this eval
          const runsWithExpectations = {};
          for (const config of configGroups) {
            runsWithExpectations[config] = evalRuns.filter(r => r.configuration === config && r.expectations && r.expectations.length > 0);
          }
          const hasAnyExpectations = Object.values(runsWithExpectations).some(runs => runs.length > 0);
          if (hasAnyExpectations) {
            // Collect all unique assertion texts across all configs
            const allAssertions = [];
            const seen = new Set();
            for (const config of configGroups) {
              for (const run of runsWithExpectations[config]) {
                for (const exp of (run.expectations || [])) {
                  if (!seen.has(exp.text)) {
                    seen.add(exp.text);
                    allAssertions.push(exp.text);
                  }
                }
              }
            }

            html += '<table class="benchmark-table" style="margin-top: 0.5rem;">';
            html += "<thead><tr><th>Assertion</th>";
            for (const config of configGroups) {
              const label = config.replace(/_/g, " ").replace(/\b\w/g, c => c.toUpperCase());
              html += "<th>" + escapeHtml(label) + "</th>";
            }
            html += "</tr></thead><tbody>";

            for (const assertionText of allAssertions) {
              html += "<tr><td>" + escapeHtml(assertionText) + "</td>";

              for (const config of configGroups) {
                html += "<td>";
                for (const run of runsWithExpectations[config]) {
                  const exp = (run.expectations || []).find(e => e.text === assertionText);
                  if (exp) {
                    const cls = exp.passed ? "benchmark-delta-positive" : "benchmark-delta-negative";
                    const icon = exp.passed ? "\u2713" : "\u2717";
                    html += '<span class="' + cls + '" title="Run ' + run.run_number + ': ' + escapeHtml(exp.evidence || "") + '">' + icon + "</span> ";
                  } else {
                    html += " ";
                  }
                }
                html += "</td>";
              }
              html += "</tr>";
            }
            html += "</tbody></table>";
          }
        }
      }

      // Notes
      if (notes.length > 0) {
        html += '<div class="benchmark-notes">';
        html += "<h3>Analysis Notes</h3>";
        html += "<ul>";
        for (const note of notes) {
          html += "<li>" + escapeHtml(note) + "</li>";
        }
        html += "</ul></div>";
      }

      container.innerHTML = html;
    }

    // ---- Start ----
    init();
    renderBenchmark();
  </script>
</body>
</html>
